{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"10mPl9z0KYZUS5ubRzBwqzaMoBQv7zdW-","authorship_tag":"ABX9TyOUsHUZOWCCPyJvPKIpY/VG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# RLHF Fine-Tuning"],"metadata":{"id":"4kQRguV413i9"}},{"cell_type":"markdown","source":["## Load the SFT and Reward Models"],"metadata":{"id":"DEy3u4dV2BPc"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"pBUiukhRTUGz","executionInfo":{"status":"ok","timestamp":1749831819158,"user_tz":-60,"elapsed":8819,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"outputs":[],"source":["%cp /content/drive/MyDrive/copy\\ files/reward_model.pt .\n","%cp /content/drive/MyDrive/copy\\ files/sft_model_epoch_1.zip ."]},{"cell_type":"code","source":["!unzip sft_model_epoch_1.zip"],"metadata":{"id":"KeU5RA6RUK2E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Reward model"],"metadata":{"id":"zXKIA80F2NK_"}},{"cell_type":"code","source":["import torch\n","from typing import Optional\n","from torch import nn\n","import numpy as np\n","from transformers import AutoModelForCausalLM\n","\n","class RewardHead(nn.Module):\n","    \"\"\"\n","    The RewardHead class implements a head for GPT2\n","    that returns a scalar for each output token.\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.hidden_size = config.hidden_size\n","        self.reward = nn.Linear(self.hidden_size, 1)\n","        self._post_init()\n","\n","    def _post_init(self):\n","        nn.init.normal_(self.reward.weight, std=(1.0 / np.sqrt(self.hidden_size + 1)))\n","        nn.init.zeros_(self.reward.bias)\n","\n","    def forward(self, hidden_states):\n","        output = hidden_states\n","        return self.reward(output)\n","\n","\n","class GPT2RewardModel(nn.Module):\n","    \"\"\"\n","    GPT2 model with a reward head on top.\n","    \"\"\"\n","\n","    def __init__(self, model_name):\n","        super().__init__()\n","        self.llm = AutoModelForCausalLM.from_pretrained(model_name)\n","        # config = self.llm.config\n","        # Add the reward head\n","        self.reward_head = RewardHead(self.llm.config)\n","\n","    def forward(\n","        self,\n","        input_ids,\n","        attention_mask,\n","    ) -> Optional[torch.FloatTensor]:\n","\n","        transformer_outputs = self.llm.forward(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            output_hidden_states = True,\n","        )\n","\n","        # Get the last hidden state\n","        last_hidden_state = transformer_outputs.hidden_states[-1]\n","\n","        # Apply the reward head\n","        rewards = self.reward_head(last_hidden_state).squeeze(-1)\n","\n","        return torch.sigmoid(rewards)\n","\n"],"metadata":{"id":"0g0VIlFvUgLA","executionInfo":{"status":"ok","timestamp":1749831836391,"user_tz":-60,"elapsed":8283,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["model_name = \"gpt2\"\n","reward_model = GPT2RewardModel(model_name)\n","reward_model.load_state_dict(torch.load(\"reward_model.pt\", map_location='cpu'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mbFZryb3Um49","executionInfo":{"status":"ok","timestamp":1749831850046,"user_tz":-60,"elapsed":13654,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"c67a38cf-1af4-44d9-ace8-9f75c74fcc12"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["## Model with Value Head"],"metadata":{"id":"juFUbSNfVn2U"}},{"cell_type":"code","source":["import torch\n","from typing import Optional\n","from torch import nn\n","import numpy as np\n","from transformers import AutoModelForCausalLM\n","\n","class ValueHead(nn.Module):\n","    \"\"\"\n","    The ValueHead class implements a head for GPT2\n","    that returns a scalar for each output token.\n","    \"\"\"\n","\n","    def __init__(self, config):\n","        super().__init__()\n","        self.hidden_size = config.hidden_size\n","        self.value = nn.Linear(self.hidden_size, 1)\n","        self._post_init()\n","\n","    def _post_init(self):\n","        nn.init.normal_(self.value.weight, std=(1.0 / np.sqrt(self.hidden_size + 1)))\n","        nn.init.zeros_(self.value.bias)\n","\n","    def forward(self, hidden_states):\n","        output = hidden_states\n","        return self.value(output)\n","\n","\n","class ModelForCausalLMWithValueHead(nn.Module):\n","    \"\"\"\n","    GPT2 model with a value head on top.\n","    \"\"\"\n","\n","    def __init__(self, model_path):\n","        super().__init__()\n","        self.llm = AutoModelForCausalLM.from_pretrained(model_path)\n","        # config = self.llm.config\n","        # Add the reward head\n","        self.v_head = ValueHead(self.llm.config)\n","\n","    def forward(\n","        self,\n","        input_ids,\n","        attention_mask,\n","    ) -> Optional[torch.FloatTensor]:\n","\n","        transformer_outputs = self.llm.forward(\n","            input_ids,\n","            attention_mask=attention_mask,\n","            output_hidden_states = True,\n","        )\n","        lm_logits = transformer_outputs.logits\n","        # Get the last hidden state\n","        last_hidden_state = transformer_outputs.hidden_states[-1]\n","\n","        # Apply the reward head\n","        value = self.v_head(last_hidden_state).squeeze(-1)\n","        return lm_logits, value\n","\n","    def generate(self, *args, **kwargs):\n","        return self.llm.generate(*args, **kwargs)\n"],"metadata":{"id":"sQo4pbqGVv3A","executionInfo":{"status":"ok","timestamp":1749831850046,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model_path = './sft_model_epoch_1'\n","model = ModelForCausalLMWithValueHead(model_path)"],"metadata":{"id":"X3xGmHI8W0Q0","executionInfo":{"status":"ok","timestamp":1749831850332,"user_tz":-60,"elapsed":288,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Preparing Dataset"],"metadata":{"id":"UqUTbr_DXA0j"}},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token"],"metadata":{"id":"jpFxrOLgXTkz","executionInfo":{"status":"ok","timestamp":1749831850900,"user_tz":-60,"elapsed":568,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["%pip install datasets==3.5.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NeWPFknOXf_2","executionInfo":{"status":"ok","timestamp":1749831855272,"user_tz":-60,"elapsed":4370,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"c56fcdba-a98b-475a-96f7-3d496d49677f","collapsed":true},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets==3.5.0 in /usr/local/lib/python3.11/dist-packages (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.18.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.3.7)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.70.15)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets==3.5.0) (2024.12.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (3.11.15)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (0.32.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==3.5.0) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.6.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (6.4.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (0.3.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.5.0) (1.20.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets==3.5.0) (1.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==3.5.0) (2025.4.26)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.5.0) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.5.0) (1.17.0)\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","dataset = load_dataset(\"sst2\")\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Og0-yavAXi36","executionInfo":{"status":"ok","timestamp":1749831859812,"user_tz":-60,"elapsed":4538,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"f537d916-b1ee-40d6-e78b-e22b3b991058"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['idx', 'sentence', 'label'],\n","        num_rows: 67349\n","    })\n","    validation: Dataset({\n","        features: ['idx', 'sentence', 'label'],\n","        num_rows: 872\n","    })\n","    test: Dataset({\n","        features: ['idx', 'sentence', 'label'],\n","        num_rows: 1821\n","    })\n","})"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["ds_train, ds_val = dataset['train'], dataset['validation']"],"metadata":{"id":"r8r6wI0ZXpqS","executionInfo":{"status":"ok","timestamp":1749831859817,"user_tz":-60,"elapsed":2,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Filtering"],"metadata":{"id":"f-Krfsh5Xwq5"}},{"cell_type":"code","source":["len(ds_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w0gae7XcX9ri","executionInfo":{"status":"ok","timestamp":1749831859832,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"9bd63911-08d7-4902-fd31-bd317e15cac1"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["67349"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["ds_train = ds_train.filter(lambda x: len(x['sentence'].split(' ')) > 8)"],"metadata":{"id":"MXq59PWPX_CC","executionInfo":{"status":"ok","timestamp":1749831859926,"user_tz":-60,"elapsed":93,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["len(ds_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uyt4_oCIYRO6","executionInfo":{"status":"ok","timestamp":1749831859938,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"bc067e19-c98d-4e35-dbfe-e24ef63f2113"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["31105"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["ds_val = ds_val.filter(lambda x: len(x['sentence'].split(' ')) > 8)"],"metadata":{"id":"D--0rAUSYTaT","executionInfo":{"status":"ok","timestamp":1749831859952,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["len(ds_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TuTJnI0VYXbl","executionInfo":{"status":"ok","timestamp":1749831859972,"user_tz":-60,"elapsed":18,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"d6234819-5378-43d8-b230-f0e61fd19771"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["807"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import random\n","input_min_token_length = 2\n","input_max_token_length = 8\n","input_token_length_range = list(range(input_min_token_length, input_max_token_length))\n","print(input_token_length_range)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MVO2_DDEYYif","executionInfo":{"status":"ok","timestamp":1749831859991,"user_tz":-60,"elapsed":18,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"71a0f9f7-8e09-4444-9ba9-c665c8fcc476"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["[2, 3, 4, 5, 6, 7]\n"]}]},{"cell_type":"code","source":["random.choice(input_token_length_range)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4VD3Rny7YvxX","executionInfo":{"status":"ok","timestamp":1749831860077,"user_tz":-60,"elapsed":85,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"5ef76e0e-2a75-42c8-c3f1-f1b6a1adfad4"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["def tokenize(sample):\n","    input_size = random.choice(input_token_length_range)\n","    sample['input_ids'] = tokenizer.encode(sample['sentence'])[:input_size]\n","    sample['attention_mask'] = [1] * len(sample['input_ids'])\n","    sample['query'] = tokenizer.decode(sample['input_ids'])\n","    return sample\n","\n","map_kwargs = {\n","    \"batched\": False,\n","    \"remove_columns\": ['idx', 'sentence', 'label']\n","}\n","\n","tokenized_dataset_train = ds_train.map(tokenize, **map_kwargs)\n","tokenized_dataset_val = ds_val.map(tokenize, **map_kwargs)\n"],"metadata":{"id":"iB0Msyo7Y6B5","executionInfo":{"status":"ok","timestamp":1749831860155,"user_tz":-60,"elapsed":76,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset_train.set_format(type='torch')\n","tokenized_dataset_val.set_format(type='torch')"],"metadata":{"id":"dmragNXwZxEz","executionInfo":{"status":"ok","timestamp":1749831860157,"user_tz":-60,"elapsed":1,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["tokenized_dataset_train[6]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A_zwH0J2Z__M","executionInfo":{"status":"ok","timestamp":1749831860213,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"bc8d9625-acd4-4c7f-f351-78d02c03f01e"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([1640,  883]),\n"," 'attention_mask': tensor([1, 1]),\n"," 'query': 'for those'}"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["REWARD_TOKEN_ID = tokenizer.eos_token_id"],"metadata":{"id":"FxG13E1haCh7","executionInfo":{"status":"ok","timestamp":1749831860215,"user_tz":-60,"elapsed":1,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","batch_size = 32\n","\n","def collator(batch):\n","    return dict((key, [d[key] for d in batch]) for key in batch[0])\n","\n","train_dataloader = DataLoader(tokenized_dataset_train, batch_size=batch_size, collate_fn=collator, shuffle=True)\n","val_dataloader = DataLoader(tokenized_dataset_val, batch_size=batch_size, collate_fn=collator, shuffle=True)"],"metadata":{"id":"XqjWwhamIGH-","executionInfo":{"status":"ok","timestamp":1749831860216,"user_tz":-60,"elapsed":1,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["batch = next(iter(train_dataloader))\n","batch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"uCy92clTKgl7","executionInfo":{"status":"ok","timestamp":1749831860233,"user_tz":-60,"elapsed":16,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"82976625-48f9-4a19-85a9-1f37eb9639b1"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [tensor([ 271,  257, 5391,   12,   86, 2175]),\n","  tensor([8340,  257, 3807]),\n","  tensor([23442,   262]),\n","  tensor([19188,   326,  4077, 29815,   550,  3750,   257]),\n","  tensor([  292, 29408]),\n","  tensor([5832,  705,  260, 9431]),\n","  tensor([  338,  3729,   281, 30438,  1700,   286,   326]),\n","  tensor([1640,  257]),\n","  tensor([ 361,  262, 2587,  318, 3731,  290]),\n","  tensor([  86, 4066,  656,  262]),\n","  tensor([ 271,  257, 1339,  286, 1165,  867]),\n","  tensor([  533, 47300,   290,  7744,   503]),\n","  tensor([ 72, 588, 326, 895, 342, 837, 339]),\n","  tensor([15596,   935,  5442,  6616,  1108,   326]),\n","  tensor([   8, 1266, 2499, 1833]),\n","  tensor([ 1169,   442,   378,   559, 14448,   284,   374]),\n","  tensor([  944,    12, 13716,   284,  5698,   257,  9155]),\n","  tensor([ 1169, 32339,   290,   262,   584,  3435,  1949]),\n","  tensor([  271,   517,   287,  1842,   351, 36666,  9449]),\n","  tensor([21754,  4729, 44918, 15579, 14720,   329,  3081]),\n","  tensor([   64, 41456,   837]),\n","  tensor([ 338,  281, 1998,  287, 4547,  257]),\n","  tensor([ 505,  286,  262, 1266, 1175, 6918]),\n","  tensor([41357, 14750,   326,  5380,   284, 28763, 14368]),\n","  tensor([8505,  837,  340,  705,   82,  355]),\n","  tensor([34330,   621,  1103,  5538,   837,   304,  2680]),\n","  tensor([4360,  340,  318]),\n","  tensor([ 1350, 13206,   837, 28297]),\n","  tensor([21754,   423,   587]),\n","  tensor([15344,    82]),\n","  tensor([ 1169,  1862,  5788,   389,  1165, 13779]),\n","  tensor([ 292,  257, 3437])],\n"," 'attention_mask': [tensor([1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1]),\n","  tensor([1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1]),\n","  tensor([1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1]),\n","  tensor([1, 1, 1, 1]),\n","  tensor([1, 1, 1]),\n","  tensor([1, 1]),\n","  tensor([1, 1, 1, 1, 1, 1]),\n","  tensor([1, 1, 1])],\n"," 'query': ['is a dim-witted',\n","  'watch a movie',\n","  'got the',\n","  'would that greengrass had gone a',\n","  'as patriot',\n","  \"you 're convinced\",\n","  \"'s certainly an invaluable record of that\",\n","  'for a',\n","  'if the material is slight and',\n","  'wander into the',\n","  'is a case of too many',\n","  'are jarring and deeply out',\n","  'i like that smith , he',\n","  'eventually winning squareness that',\n","  ') best works understand',\n","  'the chateau belongs to r',\n","  'self-control to guide a loose',\n","  'the narrator and the other characters try',\n","  'is more in love with strangeness',\n","  'should attract upscale audiences hungry for quality',\n","  'a penetrating ,',\n","  \"'s an experience in understanding a\",\n","  'one of the best war movies',\n","  'generic scripts that seek to remake slee',\n","  \"yes , it 's as\",\n","  'rather than real figures , elling',\n","  'but it is',\n","  'be compelling , amusing',\n","  'should have been',\n","  'turns',\n","  'the young stars are too cute',\n","  'as a director']}"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["output_min_length = 5\n","output_max_length = 16\n","\n","# https://huggingface.co/docs/trl/how_to_train#how-to-generate-text-for-training\n","\n","generation_kwargs = {\n","    \"min_length\": -1,\n","    \"top_k\": 0.0,\n","    \"top_p\": 1.0,\n","    \"do_sample\": True,\n","    \"pad_token_id\": tokenizer.pad_token_id\n","}"],"metadata":{"id":"W23GG8TLKv43","executionInfo":{"status":"ok","timestamp":1749831860243,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["## Sample Generation"],"metadata":{"id":"vcIGNP_Zh05i"}},{"cell_type":"code","source":["new_tokens = random.choice(list(range(output_min_length, output_max_length)))\n","generation_kwargs[\"max_new_tokens\"] = new_tokens\n","sample = tokenizer('Hi, this')\n","sample"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NJrexC5oh2W8","executionInfo":{"status":"ok","timestamp":1749831860291,"user_tz":-60,"elapsed":48,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"b5b4e460-95ac-4e67-cc0e-5ee77321acf1"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [17250, 11, 428], 'attention_mask': [1, 1, 1]}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["query_response = model.generate(\n","    input_ids=torch.tensor(sample['input_ids']).unsqueeze(0),\n","    attention_mask=torch.tensor(sample['attention_mask']).unsqueeze(0),\n","    **generation_kwargs\n","    ).squeeze(0)\n","query_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Afkv6jkjiJgp","executionInfo":{"status":"ok","timestamp":1749831864193,"user_tz":-60,"elapsed":3913,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"8d27b366-c99a-41b5-f3c7-a96cd7c7bdfe"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([17250,    11,   428,   318, 17774,   220,  1849,   220,   220,   220,\n","          220,   220,   220,   220])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["tokenizer.decode(query_response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"eh4EEAF6ioeQ","executionInfo":{"status":"ok","timestamp":1749831864194,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"3bb493ab-32a7-42f1-ee14-a17b7d554145"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hi, this is entertaining \\xa0       '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["with torch.no_grad():\n","    query_response_score = torch.cat([query_response, torch.tensor([REWARD_TOKEN_ID])])\n","    attention_mask = torch.ones_like(query_response_score, dtype=torch.long)\n","    score = reward_model(query_response_score.unsqueeze(0), attention_mask.unsqueeze(0)).squeeze(0)[-1]\n","score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V3Np4NQ_iuAX","executionInfo":{"status":"ok","timestamp":1749831864442,"user_tz":-60,"elapsed":250,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"05169fda-d52d-4da6-84a5-dec158ad6e08"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.9943)"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["## Batch Generation"],"metadata":{"id":"CLxKzwl8jxQ_"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","reward_model = reward_model.to(device)\n","\n","query_tensors = batch['input_ids']\n","query_attention_masks = batch['attention_mask']\n","\n","response_tensors = []\n","query_response_tensors = []\n","score_tensors = []\n","\n","for i, query in enumerate(query_tensors):\n","    query = query.to(device)\n","    query_attention_mask = query_attention_masks[i].to(device)\n","    new_tokens = random.choice(list(range(output_min_length, output_max_length)))\n","    generation_kwargs[\"max_new_tokens\"] = new_tokens\n","    query_response = model.generate(\n","        input_ids=query.unsqueeze(0),\n","        attention_mask=query_attention_mask.unsqueeze(0),\n","        **generation_kwargs\n","    ).squeeze(0)\n","\n","    response_len = len(query_response) - len(query)\n","    response_tensors.append(query_response[-response_len:])\n","    query_response_tensors.append(query_response)\n","\n","    with torch.no_grad():\n","        query_response_score = torch.cat([query_response, torch.tensor([REWARD_TOKEN_ID]).to(device)])\n","        attention_mask = torch.ones_like(query_response_score, dtype=torch.long)\n","        score = reward_model(query_response_score.unsqueeze(0), attention_mask.unsqueeze(0)).squeeze(0)[-1]\n","        score = 2 * (score - 0.5)\n","    score_tensors.append(score)\n","\n","batch[\"response\"] = [tokenizer.decode(response) for response in response_tensors]\n","print(batch['response'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMyH9qhQj8Fg","executionInfo":{"status":"ok","timestamp":1749831874113,"user_tz":-60,"elapsed":9670,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"e3f47a04-c647-4dd7-ebe2-260d56bb5c98"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[' hunk of a movie .   ', ' but fail to make it feel authentic      ', ' edge of his seat to bring this nicely made comedy to', ' step further ?        ', ' in nature     could have', ' huston is smart .     !', ' time period. \\xa0      ', ' nuance that few such one-dimensional thrillers could ever hope to', ' under-designed or ', \" realm of one man 's farts , like neither a short movie nor\", ' thin-skinned kids being forced to watch overexposed , too forced to', ' of place in every frame \\xa0of the film  ', ' knows how to get the ball rolling , hitting his target', ' is extraordinary .            ', ' state conscience  and a condition had to be', 'alph polanski  \\xa0and there are some', ' storyline  \\ue607  \\ue607', ' desperately to convince -- or even understand -- the audience that this is', ' often than in love with the story itself', ' entertainment    ', ' deeply affecting examination of a genteel two-hour', ' theme episode , encountering it with freshness and curiousity', ' ever made , a film that deserves every little one it provides', 'pless in seattle like none other ianapolis ! ', \" if people did n't just drag each other down more emotionally a little bit\", ' makes a compelling case that international law still forces governments to', ' some of the best of the bunch , even', ' , complex stories  ', ' manufactured      for', ' out to be a surprisingly enjoyable one iced for the drink iced ', ' at 9-11 to make fresh material', ' lamenting iced birthday party crowds iced']\n"]}]},{"cell_type":"markdown","source":["## Compute Reward"],"metadata":{"id":"Z1K4nAUG5fes"}},{"cell_type":"markdown","source":["$\\text {reward} = \\text {score} - \\log (\\frac {\\pi^{RL}_\\theta} {\\pi^{SFT}})$"],"metadata":{"id":"d-zd0KK85pGT"}},{"cell_type":"code","source":["from copy import deepcopy\n","sft_model = deepcopy(model)"],"metadata":{"id":"aW8X18-Mlb3v","executionInfo":{"status":"ok","timestamp":1749831874187,"user_tz":-60,"elapsed":75,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["from transformers import DataCollatorWithPadding\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"sFAE8zQPT-uP","executionInfo":{"status":"ok","timestamp":1749831874225,"user_tz":-60,"elapsed":27,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["input_data = data_collator([\n","    {'input_ids': ids,\n","     'attention_mask': torch.ones_like(ids)} for ids in query_response_tensors\n","]).to(device)\n","input_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hi6IhpByUWWq","executionInfo":{"status":"ok","timestamp":1749831874299,"user_tz":-60,"elapsed":73,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"9c1f8bc3-ada9-4952-9742-1b6a5872ca0d","collapsed":true},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': tensor([[  271,   257,  5391,    12,    86,  2175,   289,  2954,   286,   257,\n","          3807,   764,   220,   220,   220, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [ 8340,   257,  3807,   475,  2038,   284,   787,   340,  1254, 16425,\n","           220,   220,   220,   220,   220,   220, 50256, 50256, 50256, 50256,\n","         50256],\n","        [23442,   262,  5743,   286,   465,  5852,   284,  2222,   428, 16576,\n","           925, 10997,   284, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [19188,   326,  4077, 29815,   550,  3750,   257,  2239,  2252,  5633,\n","           220,   220,   220,   220,   220,   220,   220,   220, 50256, 50256,\n","         50256],\n","        [  292, 29408,   287,  3450,   220,   220,   220,   220,   714,   423,\n","         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [ 5832,   705,   260,  9431, 33376,   261,   318,  4451,   764,   220,\n","           220,   220,   220,  5145, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [  338,  3729,   281, 30438,  1700,   286,   326,   640,  2278,    13,\n","           220,  1849,   220,   220,   220,   220,   220,   220, 50256, 50256,\n","         50256],\n","        [ 1640,   257, 47128,   326,  1178,   884,   530,    12, 19577, 28576,\n","           364,   714,  1683,  2911,   284, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [  361,   262,  2587,   318,  3731,   290,   739,    12, 30473,   393,\n","           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [   86,  4066,   656,   262, 13360,   286,   530,   582,   705,    82,\n","           277,  5889,   837,   588,  6159,   257,  1790,  3807,  4249, 50256,\n","         50256],\n","        [  271,   257,  1339,   286,  1165,   867,  7888,    12, 41412,  3988,\n","           852,  4137,   284,  2342, 43656,    87, 29813,   837,  1165,  4137,\n","           284],\n","        [  533, 47300,   290,  7744,   503,   286,  1295,   287,   790,  5739,\n","           220,  1849,  1659,   262,  2646,   220,   220, 50256, 50256, 50256,\n","         50256],\n","        [   72,   588,   326,   895,   342,   837,   339,  4206,   703,   284,\n","           651,   262,  2613, 10708,   837,  9008,   465,  2496, 50256, 50256,\n","         50256],\n","        [15596,   935,  5442,  6616,  1108,   326,   318, 11359,   764,   220,\n","           220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n","           220],\n","        [    8,  1266,  2499,  1833,  1181, 18346,   220,   290,   257,  4006,\n","           550,   284,   307, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [ 1169,   442,   378,   559, 14448,   284,   374, 17307,   755, 44978,\n","           220,   220,  1849,   392,   612,   389,   617, 50256, 50256, 50256,\n","         50256],\n","        [  944,    12, 13716,   284,  5698,   257,  9155, 22992,   220,   220,\n","           170,   246,   229,   220,   220,   170,   246,   229, 50256, 50256,\n","         50256],\n","        [ 1169, 32339,   290,   262,   584,  3435,  1949, 16459,   284, 11508,\n","          1377,   393,   772,  1833,  1377,   262,  5386,   326,   428,   318,\n","         50256],\n","        [  271,   517,   287,  1842,   351, 36666,  9449,  1690,   621,   287,\n","          1842,   351,   262,  1621,  2346, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [21754,  4729, 44918, 15579, 14720,   329,  3081,  9739,   220,   220,\n","           220,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [   64, 41456,   837,  7744, 13891, 12452,   286,   257,   308, 21872,\n","           417,   734,    12,  9769, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [  338,   281,  1998,   287,  4547,   257,  7505,  4471,   837, 42398,\n","           340,   351,  4713,  1108,   290, 11040,   414, 50256, 50256, 50256,\n","         50256],\n","        [  505,   286,   262,  1266,  1175,  6918,  1683,   925,   837,   257,\n","          2646,   326, 14071,   790,  1310,   530,   340,  3769, 50256, 50256,\n","         50256],\n","        [41357, 14750,   326,  5380,   284, 28763, 14368, 14570,   287,   384,\n","          1999,   588,  4844,   584,   220,   666, 11174,  5145,   220, 50256,\n","         50256],\n","        [ 8505,   837,   340,   705,    82,   355,   611,   661,   750,   299,\n","           470,   655,  6715,  1123,   584,   866,   517, 17991,   257,  1310,\n","          1643],\n","        [34330,   621,  1103,  5538,   837,   304,  2680,  1838,   257, 13206,\n","          1339,   326,  3230,  1099,   991,  3386,  6905,   284, 50256, 50256,\n","         50256],\n","        [ 4360,   340,   318,   617,   286,   262,  1266,   286,   262,  7684,\n","           837,   772, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [ 1350, 13206,   837, 28297,   837,  3716,  3923,   220,   220, 50256,\n","         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [21754,   423,   587, 15943,   220,   220,   220,   220,   220,   329,\n","         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [15344,    82,   503,   284,   307,   257, 12362, 20050,   530,   220,\n","          3711,   329,   262,  4144,   220,  3711,   220, 50256, 50256, 50256,\n","         50256],\n","        [ 1169,  1862,  5788,   389,  1165, 13779,   379,   860,    12,  1157,\n","           284,   787,  4713,  2587, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256],\n","        [  292,   257,  3437, 23146,   278,   220,  3711, 10955,  2151, 15779,\n","           220,  3711, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n","         50256]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n","       device='cuda:0')}"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["def compute_rewards(input_data, query_tensors, response_tensors, score_tensors):\n","    with torch.no_grad():\n","        logits, values = model(**input_data) # b, seq, vocab\n","        ref_logits, _ = sft_model(**input_data)\n","        logp = torch.nn.functional.log_softmax(logits[:, :-1, :], dim=-1)\n","        ref_logp = torch.nn.functional.log_softmax(ref_logits[:, :-1, :], dim=-1)\n","\n","        labels = input_data['input_ids'][:, 1:] # b, seq\n","\n","        logp = torch.gather(logp, 2, labels.unsqueeze(-1)).squeeze(-1) # batch, seq\n","        ref_logp = torch.gather(ref_logp, 2, labels.unsqueeze(-1)).squeeze(-1) # batch, seq\n","\n","        kl = logp - ref_logp\n","        beta = 0.2\n","        rewards = - beta * kl\n","        attention_mask = input_data['attention_mask']\n","        masks = torch.zeros_like(attention_mask[:, 1:])\n","        masks[:,:] = attention_mask[:, 1:]\n","        for j in range(len(query_tensors)):\n","            start = len(query_tensors[j]) - 1\n","            end = start + len(response_tensors[j])\n","            masks[j, :start] = 0\n","            masks[j, end:] = 0\n","            rewards[j, end - 1] += score_tensors[j]\n","            rewards[j, :] *= masks[j, :]\n","            values[j, :-1] *= masks[j, :]\n","\n","    return logp, rewards, values[:, :-1], masks\n"],"metadata":{"id":"FxbbEH4eX4Ab","executionInfo":{"status":"ok","timestamp":1749831874313,"user_tz":-60,"elapsed":14,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["logprobs, rewards, values, masks = compute_rewards(input_data, query_tensors, response_tensors, score_tensors)\n","print(rewards[0])\n","print(input_data['input_ids'][0])\n","print(input_data['attention_mask'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uy9FJ_jFcyFC","executionInfo":{"status":"ok","timestamp":1749831874625,"user_tz":-60,"elapsed":311,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"d915bb0c-da19-4085-b863-c0a2517b2318"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n","        -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.9969, -0.0000, -0.0000,\n","        -0.0000, -0.0000, -0.0000, -0.0000], device='cuda:0')\n","tensor([  271,   257,  5391,    12,    86,  2175,   289,  2954,   286,   257,\n","         3807,   764,   220,   220,   220, 50256, 50256, 50256, 50256, 50256,\n","        50256], device='cuda:0')\n","tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n","       device='cuda:0')\n"]}]},{"cell_type":"code","source":["print(masks[0])\n","print(values[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBHebohxdFR5","executionInfo":{"status":"ok","timestamp":1749831874626,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"dcb8d56a-65d8-4d85-ae52-06e4aff70861"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n","       device='cuda:0')\n","tensor([-0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -1.6054, -0.1053, -1.0586,\n","        -1.0855, -0.2100, -1.4899,  3.4527,  0.9113,  1.7163,  0.0000, -0.0000,\n","        -0.0000, -0.0000, -0.0000, -0.0000], device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["## Compute Advantage"],"metadata":{"id":"hhnlh9TEeH-h"}},{"cell_type":"code","source":["def masked_mean(values, mask):\n","    return (values * mask).sum() / mask.sum()\n","\n","def masked_var(values, mask):\n","    mean = masked_mean(values, mask)\n","    centred_values = values - mean\n","    return masked_mean(centred_values ** 2, mask)\n","\n","def masked_whiten(values, mask):\n","    mean, var = masked_mean(values, mask), masked_var(values, mask)\n","    whitened = (values - mean) * torch.rsqrt(var + 1e-8)\n","    whitened += mean\n","    return whitened\n","\n","def compute_advantage(rewards, values, masks):\n","    lastgae = 0.0\n","    advantage_reversed = []\n","    seq_length = rewards.shape[-1]\n","    gamma, lam = 1.0, 0.95\n","\n","    for t in reversed(range(seq_length)):\n","        nextvalues = values[:, t + 1] if t < seq_length - 1 else 0.0\n","        delta = rewards[:, t] + gamma * nextvalues - values[:, t]\n","        lastgae = delta + gamma * lam * lastgae\n","        advantage_reversed.append(lastgae)\n","    advantages = torch.stack(advantage_reversed[::-1], dim=1)\n","    advantages = masked_whiten(advantages, masks)\n","\n","    returns = advantages + values\n","    return advantages, returns\n"],"metadata":{"id":"6rL-IzH8eVZN","executionInfo":{"status":"ok","timestamp":1749831874653,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["advantages, returns = compute_advantage(rewards, values, masks)\n","print(advantages[0])\n","print(returns[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8ZTjweyijUu","executionInfo":{"status":"ok","timestamp":1749831874669,"user_tz":-60,"elapsed":15,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"a8b30f39-5163-4b87-df51-24f853dc7106"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 0.1104,  0.0946,  0.0779,  0.0603,  0.0418,  0.9713,  0.1140,  0.6619,\n","         0.6910,  0.1882,  0.9330, -1.9612, -0.5839, -1.1121,  0.4116,  0.4116,\n","         0.4116,  0.4116,  0.4116,  0.4116], device='cuda:0')\n","tensor([ 0.1104,  0.0946,  0.0779,  0.0603,  0.0418, -0.6341,  0.0088, -0.3967,\n","        -0.3945, -0.0218, -0.5569,  1.4915,  0.3275,  0.6042,  0.4116,  0.4116,\n","         0.4116,  0.4116,  0.4116,  0.4116], device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["## Mini-batch PPO Training"],"metadata":{"id":"dACSgd1ripo_"}},{"cell_type":"markdown","source":["### Training Config"],"metadata":{"id":"kTTWJrvLxaUz"}},{"cell_type":"code","source":["learning_rate = 1e-5\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"],"metadata":{"id":"UsqMGuocxdJr","executionInfo":{"status":"ok","timestamp":1749831874702,"user_tz":-60,"elapsed":31,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["np.random.permutation(batch_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwYclizbyNg1","executionInfo":{"status":"ok","timestamp":1749831874707,"user_tz":-60,"elapsed":4,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"6fa06eb9-208e-4cc7-cec4-37b5935d8ebe"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([13, 17, 20,  7, 26,  1, 25, 23, 11, 21,  4, 14,  6,  3,  9,  2,  0,\n","       15,  5, 10, 30, 19, 29, 22, 24,  8, 28, 12, 27, 18, 16, 31])"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["mini_batch_size = 4\n","ppo_epochs = 4\n","\n","cliprange_ratio = 0.2\n","\n","v_loss_coeff = 0.1\n","\n","ratio_threshold = 10\n","\n","def compute_loss(old_logprobs, values, logprobs, vpreds, masks, advantages, returns):\n","    ratio = torch.exp(logprobs - old_logprobs)\n","    pg_loss1 = - ratio * advantages\n","    pg_loss2 = - torch.clamp(ratio, 1 - cliprange_ratio, 1 + cliprange_ratio) * advantages\n","    pg_loss = masked_mean(torch.max(pg_loss1, pg_loss2), masks)\n","\n","    v_loss = masked_mean((vpreds - returns) ** 2, masks)\n","    loss = pg_loss + v_loss_coeff * v_loss\n","\n","    avg_ratio = masked_mean(ratio, masks)\n","    if avg_ratio > ratio_threshold:\n","        pg_loss = pg_loss * 0.0\n","        v_loss = v_loss * 0.0\n","        loss = loss * 0.0\n","\n","    return loss, v_loss\n","\n","def mini_batch_train():\n","    for ep in range(ppo_epochs):\n","        batch_inds = np.random.permutation(batch_size)\n","\n","        for start in range(0, batch_size, mini_batch_size):\n","            end = start + mini_batch_size\n","            mini_batch_inds = batch_inds[start:end]\n","\n","            mb_model_inputs = {\n","                'input_ids': input_data['input_ids'][mini_batch_inds],\n","                'attention_mask': input_data['attention_mask'][mini_batch_inds]\n","            }\n","            mb_logits, mb_vpreds = model(**mb_model_inputs)\n","            mb_logits = torch.nn.functional.log_softmax(mb_logits[:, :-1, :], dim=-1)\n","            mb_logprobs = torch.gather(mb_logits, 2, mb_model_inputs['input_ids'][:, 1:].unsqueeze(-1)).squeeze(-1)\n","\n","            loss, loss_v = compute_loss(\n","                logprobs[mini_batch_inds],\n","                values[mini_batch_inds],\n","                mb_logprobs,\n","                mb_vpreds[:, :-1],\n","                masks[mini_batch_inds],\n","                advantages[mini_batch_inds],\n","                returns[mini_batch_inds]\n","            )\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            print('loss/total', loss.item())\n","    print('mini-batch training finished')\n","\n"],"metadata":{"id":"vhiRjkGCzBLI","executionInfo":{"status":"ok","timestamp":1749831874736,"user_tz":-60,"elapsed":29,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["mini_batch_train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6TmyCw7g9zGU","executionInfo":{"status":"ok","timestamp":1749831879070,"user_tz":-60,"elapsed":4332,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"01adff5b-42b0-4b44-b76a-a448bf0d731b"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["loss/total -0.6469668745994568\n","loss/total -1.084718942642212\n","loss/total -0.9519063234329224\n","loss/total -0.5013611912727356\n","loss/total -0.7945360541343689\n","loss/total -0.4254860281944275\n","loss/total -1.0511527061462402\n","loss/total -0.9178730845451355\n","loss/total -0.31340065598487854\n","loss/total -1.4144445657730103\n","loss/total -0.74092698097229\n","loss/total -1.5609691143035889\n","loss/total -0.8986895084381104\n","loss/total -1.1131693124771118\n","loss/total -1.3536183834075928\n","loss/total -0.83698570728302\n","loss/total -0.8659009337425232\n","loss/total -1.666944980621338\n","loss/total -0.9409258365631104\n","loss/total -1.2696202993392944\n","loss/total -0.6142494678497314\n","loss/total -1.3109718561172485\n","loss/total -0.7585713267326355\n","loss/total -0.9758541584014893\n","loss/total -1.3880150318145752\n","loss/total -0.833629310131073\n","loss/total -0.638252317905426\n","loss/total -1.1900427341461182\n","loss/total -0.4314558207988739\n","loss/total -1.388943076133728\n","loss/total -1.1693115234375\n","loss/total -1.4005227088928223\n","mini-batch training finished\n"]}]},{"cell_type":"markdown","source":["## Train RLHF"],"metadata":{"id":"rcZPLHlb91la"}},{"cell_type":"code","source":["num_epochs = 1\n","\n","for epoch in range(num_epochs):\n","    for batch in train_dataloader:\n","        # Generate responses\n","        query_tensors = batch['input_ids']\n","        query_attention_masks = batch['attention_mask']\n","\n","        response_tensors = []\n","        query_response_tensors = []\n","        score_tensors = []\n","\n","        for i, query in enumerate(query_tensors):\n","            query = query.to(device)\n","            query_attention_mask = query_attention_masks[i].to(device)\n","            new_tokens = random.choice(list(range(output_min_length, output_max_length)))\n","            generation_kwargs[\"max_new_tokens\"] = new_tokens\n","            query_response = model.generate(\n","                input_ids=query.unsqueeze(0),\n","                attention_mask=query_attention_mask.unsqueeze(0),\n","                **generation_kwargs\n","                ).squeeze(0)\n","\n","            response_len = len(query_response) - len(query)\n","            response_tensors.append(query_response[-response_len:])\n","            query_response_tensors.append(query_response)\n","\n","            with torch.no_grad():\n","                query_response_score = torch.cat([query_response, torch.tensor([REWARD_TOKEN_ID]).to(device)])\n","                attention_mask = torch.ones_like(query_response_score, dtype=torch.long)\n","                score = reward_model(query_response_score.unsqueeze(0), attention_mask.unsqueeze(0)).squeeze(0)[-1]\n","                score = 2 * (score - 0.5)\n","            score_tensors.append(score)\n","\n","        input_data = data_collator([\n","            {\n","                'input_ids': ids,\n","                'attention_mask': torch.ones_like(ids)\n","            }\n","            for ids in query_response_tensors\n","        ]).to(device)\n","\n","        # rewards and advantages\n","        logprobs, rewards, values, masks = compute_rewards(input_data, query_tensors, response_tensors, score_tensors)\n","        advantages, returns = compute_advantage(rewards, values, masks)\n","\n","        # mini batch training\n","        mini_batch_train()\n","    print(f'epoch {epoch + 1} finished')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Tsh0CnDR-zyN","executionInfo":{"status":"error","timestamp":1749832594860,"user_tz":-60,"elapsed":715773,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"efc30ff5-0ece-43c4-f59b-42f1204740e4"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["loss/total -0.2181205004453659\n","loss/total -0.27999866008758545\n","loss/total -0.04347766935825348\n","loss/total -0.09446786344051361\n","loss/total -0.2365225851535797\n","loss/total -0.1936279833316803\n","loss/total -0.18569737672805786\n","loss/total 0.015834838151931763\n","loss/total -0.3695436716079712\n","loss/total -0.3765247166156769\n","loss/total -0.1999007761478424\n","loss/total -0.04889871925115585\n","loss/total -0.3259511888027191\n","loss/total -0.5705932378768921\n","loss/total -0.5666579008102417\n","loss/total 0.31472232937812805\n","loss/total -0.24711640179157257\n","loss/total 0.11507843434810638\n","loss/total -0.6125611066818237\n","loss/total -0.2456435263156891\n","loss/total -0.31063202023506165\n","loss/total -0.14951065182685852\n","loss/total -0.42727845907211304\n","loss/total -0.6759032011032104\n","loss/total -0.24428074061870575\n","loss/total -0.3461518883705139\n","loss/total -0.35590457916259766\n","loss/total -0.20021793246269226\n","loss/total -0.36694443225860596\n","loss/total -0.5016358494758606\n","loss/total -0.2143326699733734\n","loss/total -0.49306899309158325\n","mini-batch training finished\n","loss/total 0.8737843036651611\n","loss/total -0.2574058175086975\n","loss/total -0.2869735658168793\n","loss/total -0.11288277804851532\n","loss/total 0.21997199952602386\n","loss/total -0.06540099531412125\n","loss/total 0.03750033304095268\n","loss/total 0.26856547594070435\n","loss/total -0.33656418323516846\n","loss/total -0.0010077133774757385\n","loss/total 0.3439277112483978\n","loss/total -0.11065030097961426\n","loss/total -0.2672025263309479\n","loss/total -0.20208415389060974\n","loss/total 0.1035124659538269\n","loss/total 0.27850279211997986\n","loss/total 0.35997170209884644\n","loss/total -0.11108648777008057\n","loss/total -0.8203111886978149\n","loss/total -0.08125410228967667\n","loss/total -0.1589379906654358\n","loss/total 0.061819590628147125\n","loss/total 0.06659207493066788\n","loss/total 0.06896524876356125\n","loss/total -0.11550979316234589\n","loss/total 0.09640442579984665\n","loss/total -0.11350550502538681\n","loss/total 0.10411812365055084\n","loss/total -0.6744368672370911\n","loss/total -0.10687236487865448\n","loss/total -0.28157252073287964\n","loss/total 0.2878926694393158\n","mini-batch training finished\n","loss/total -0.5110862851142883\n","loss/total 0.043207161128520966\n","loss/total 0.25745490193367004\n","loss/total 0.017292775213718414\n","loss/total 0.04336555302143097\n","loss/total 0.7122316360473633\n","loss/total 0.014019563794136047\n","loss/total -0.34832310676574707\n","loss/total -0.026365377008914948\n","loss/total 0.17387734353542328\n","loss/total -0.5190764665603638\n","loss/total 0.06531055271625519\n","loss/total 0.18070662021636963\n","loss/total -0.4159816801548004\n","loss/total -0.767680823802948\n","loss/total 0.20443499088287354\n","loss/total 0.17018567025661469\n","loss/total -0.13251034915447235\n","loss/total 0.02051462233066559\n","loss/total -0.5669979453086853\n","loss/total 0.0260532945394516\n","loss/total 0.04834117367863655\n","loss/total -0.08639385551214218\n","loss/total -0.5415786504745483\n","loss/total -0.13396108150482178\n","loss/total 0.0048922039568424225\n","loss/total -0.4679463803768158\n","loss/total -0.11526001989841461\n","loss/total 0.32295599579811096\n","loss/total -0.42963799834251404\n","loss/total -0.36095765233039856\n","loss/total -0.2806876301765442\n","mini-batch training finished\n","loss/total -0.019369259476661682\n","loss/total 0.31963756680488586\n","loss/total 0.2974044382572174\n","loss/total 0.3334428668022156\n","loss/total 0.808230459690094\n","loss/total 0.24036221206188202\n","loss/total 0.44953519105911255\n","loss/total 0.3359305262565613\n","loss/total 0.7777519822120667\n","loss/total 0.04960707202553749\n","loss/total -0.09064474701881409\n","loss/total 0.2559014558792114\n","loss/total 0.36581555008888245\n","loss/total 0.2263411283493042\n","loss/total 0.21500790119171143\n","loss/total 0.18737459182739258\n","loss/total 0.8872849941253662\n","loss/total -0.0520772859454155\n","loss/total 0.20621660351753235\n","loss/total 0.10456912964582443\n","loss/total -0.25169843435287476\n","loss/total 0.42706298828125\n","loss/total 0.3457079529762268\n","loss/total 0.02905140072107315\n","loss/total 0.4194433093070984\n","loss/total -0.05645512044429779\n","loss/total 1.0022417306900024\n","loss/total -0.08022690564393997\n","loss/total 0.08889485895633698\n","loss/total 0.4328649044036865\n","loss/total -0.1440446674823761\n","loss/total -0.025367461144924164\n","mini-batch training finished\n","loss/total -0.5637143850326538\n","loss/total 0.0973929613828659\n","loss/total 0.36193445324897766\n","loss/total 0.44934263825416565\n","loss/total -0.033277638256549835\n","loss/total 0.07700298726558685\n","loss/total 0.5473870635032654\n","loss/total -0.1654638946056366\n","loss/total -0.5692288279533386\n","loss/total 0.44925594329833984\n","loss/total 0.33262237906455994\n","loss/total -0.342991441488266\n","loss/total -0.03597485274076462\n","loss/total 0.04533671587705612\n","loss/total 0.08153575658798218\n","loss/total 0.11561871320009232\n","loss/total -0.17125123739242554\n","loss/total -0.5230503678321838\n","loss/total 0.42938363552093506\n","loss/total -0.12326968461275101\n","loss/total -0.49295684695243835\n","loss/total 0.1397906094789505\n","loss/total 0.6131668090820312\n","loss/total -0.3215183913707733\n","loss/total 0.2204713076353073\n","loss/total 0.2515600323677063\n","loss/total -0.2594572901725769\n","loss/total -0.2715844213962555\n","loss/total 0.04186186566948891\n","loss/total 0.20068377256393433\n","loss/total -0.21795500814914703\n","loss/total -0.40678325295448303\n","mini-batch training finished\n","loss/total 0.10754595696926117\n","loss/total 0.48459702730178833\n","loss/total -0.3335835337638855\n","loss/total 0.1859007328748703\n","loss/total -0.1874978244304657\n","loss/total 0.22408197820186615\n","loss/total -0.52397620677948\n","loss/total -0.19919967651367188\n","loss/total -0.3809068202972412\n","loss/total 0.19115519523620605\n","loss/total -0.09588198363780975\n","loss/total -0.44909822940826416\n","loss/total -0.1938801407814026\n","loss/total -0.4069117307662964\n","loss/total 0.4349138140678406\n","loss/total -0.32524311542510986\n","loss/total 0.10654103010892868\n","loss/total -0.30323755741119385\n","loss/total 0.056899845600128174\n","loss/total 0.1687932163476944\n","loss/total -0.8593874573707581\n","loss/total -0.35196396708488464\n","loss/total -0.16177111864089966\n","loss/total -0.6129804253578186\n","loss/total -0.39727628231048584\n","loss/total -0.5071589946746826\n","loss/total -0.6941845417022705\n","loss/total -0.19798997044563293\n","loss/total 0.08952556550502777\n","loss/total 0.12449952960014343\n","loss/total 0.13152354955673218\n","loss/total -0.22653067111968994\n","mini-batch training finished\n","loss/total 0.17731539905071259\n","loss/total -0.009271379560232162\n","loss/total 0.42101985216140747\n","loss/total -0.32711389660835266\n","loss/total -0.5759227871894836\n","loss/total -0.5594477653503418\n","loss/total -0.0835498720407486\n","loss/total 0.48264068365097046\n","loss/total 0.28204065561294556\n","loss/total -0.5163856148719788\n","loss/total -0.6123238801956177\n","loss/total 0.13423779606819153\n","loss/total -0.7338697910308838\n","loss/total 0.10051076114177704\n","loss/total 0.18117141723632812\n","loss/total -0.17721450328826904\n","loss/total -0.6239129304885864\n","loss/total -0.4196583926677704\n","loss/total -0.5269037485122681\n","loss/total 0.37294358015060425\n","loss/total -0.23308971524238586\n","loss/total -0.01913221925497055\n","loss/total -0.22156858444213867\n","loss/total 0.29929834604263306\n","loss/total 0.11550728231668472\n","loss/total 0.055135611444711685\n","loss/total -0.13073641061782837\n","loss/total -0.07576976716518402\n","loss/total -0.4483640491962433\n","loss/total -0.5676268339157104\n","loss/total -0.07273497432470322\n","loss/total -0.4517441987991333\n","mini-batch training finished\n","loss/total 0.12320756167173386\n","loss/total 0.30742526054382324\n","loss/total 0.15519282221794128\n","loss/total 0.45383360981941223\n","loss/total -0.27909669280052185\n","loss/total -0.14420443773269653\n","loss/total 0.26305001974105835\n","loss/total -0.2914503216743469\n","loss/total 0.6591908931732178\n","loss/total -0.8189489841461182\n","loss/total -0.34831953048706055\n","loss/total -0.17523595690727234\n","loss/total 0.2749727964401245\n","loss/total -0.06214790791273117\n","loss/total -0.30058521032333374\n","loss/total 0.05057680234313011\n","loss/total -0.5129448771476746\n","loss/total -0.4252893030643463\n","loss/total 0.5897255539894104\n","loss/total -0.3366754353046417\n","loss/total -0.2806742787361145\n","loss/total 0.1419707089662552\n","loss/total 0.3844682276248932\n","loss/total -0.18174436688423157\n","loss/total 0.03291044384241104\n","loss/total -0.49461373686790466\n","loss/total -0.24773845076560974\n","loss/total -0.13274648785591125\n","loss/total -0.05295155197381973\n","loss/total -0.20883706212043762\n","loss/total 0.3030880093574524\n","loss/total -0.24982436001300812\n","mini-batch training finished\n","loss/total 0.1806207150220871\n","loss/total 0.2631100118160248\n","loss/total 0.5584878325462341\n","loss/total 0.022077947854995728\n","loss/total 0.20966783165931702\n","loss/total 0.32111018896102905\n","loss/total 0.293001264333725\n","loss/total 0.025886427611112595\n","loss/total 0.33456480503082275\n","loss/total -0.026226118206977844\n","loss/total -0.3676559329032898\n","loss/total 0.028595861047506332\n","loss/total 0.2228430211544037\n","loss/total 0.7167805433273315\n","loss/total 0.063240647315979\n","loss/total 0.0852450579404831\n","loss/total 0.29914480447769165\n","loss/total 0.19461262226104736\n","loss/total -0.22120313346385956\n","loss/total -0.12745682895183563\n","loss/total 0.3814616799354553\n","loss/total -0.13258060812950134\n","loss/total -0.2586420774459839\n","loss/total 0.5372480750083923\n","loss/total 0.1463773250579834\n","loss/total 0.08174461126327515\n","loss/total 0.23616939783096313\n","loss/total -0.2011541724205017\n","loss/total 0.21903976798057556\n","loss/total -0.5114726424217224\n","loss/total -0.06538767367601395\n","loss/total 0.6020408868789673\n","mini-batch training finished\n","loss/total -0.004247397184371948\n","loss/total 0.026159964501857758\n","loss/total 0.5924760103225708\n","loss/total 0.4087144136428833\n","loss/total -0.03712830692529678\n","loss/total 0.32456323504447937\n","loss/total 0.48008280992507935\n","loss/total -0.08331003040075302\n","loss/total -0.08922968804836273\n","loss/total 0.11698299646377563\n","loss/total 0.17117735743522644\n","loss/total -0.051592640578746796\n","loss/total 0.18435834348201752\n","loss/total 0.08837629854679108\n","loss/total 0.15152204036712646\n","loss/total 0.30691131949424744\n","loss/total -0.18066814541816711\n","loss/total 0.063912034034729\n","loss/total -0.07731043547391891\n","loss/total 0.2879161238670349\n","loss/total 0.6040096282958984\n","loss/total 0.11115707457065582\n","loss/total -0.3502439558506012\n","loss/total 0.15873189270496368\n","loss/total -0.6547766327857971\n","loss/total 0.8458930253982544\n","loss/total -0.1471318155527115\n","loss/total 0.29923123121261597\n","loss/total -0.6420823931694031\n","loss/total 0.7355173230171204\n","loss/total 0.19349634647369385\n","loss/total -0.35347843170166016\n","mini-batch training finished\n","loss/total 0.5185832381248474\n","loss/total 0.34232521057128906\n","loss/total 0.38286757469177246\n","loss/total -0.0003776922821998596\n","loss/total -0.14424562454223633\n","loss/total -0.3829033374786377\n","loss/total 0.4756748676300049\n","loss/total 0.2484000027179718\n","loss/total -0.4747422933578491\n","loss/total 0.20357584953308105\n","loss/total 0.12994027137756348\n","loss/total -0.088817298412323\n","loss/total 0.13902130722999573\n","loss/total 0.4436433017253876\n","loss/total 0.5984770059585571\n","loss/total -0.6290739178657532\n","loss/total 0.14307263493537903\n","loss/total 0.46677717566490173\n","loss/total 0.0862937644124031\n","loss/total 0.30705681443214417\n","loss/total 0.34017646312713623\n","loss/total -0.3051029443740845\n","loss/total -0.09003664553165436\n","loss/total -0.7344645857810974\n","loss/total -0.09198583662509918\n","loss/total -0.35696303844451904\n","loss/total 0.41681936383247375\n","loss/total -0.3654613494873047\n","loss/total 0.1080779880285263\n","loss/total 0.14721593260765076\n","loss/total -0.0801866352558136\n","loss/total 0.29512515664100647\n","mini-batch training finished\n","loss/total -0.362618625164032\n","loss/total -0.5417959690093994\n","loss/total -0.47069939970970154\n","loss/total 0.5291215181350708\n","loss/total 0.46504268050193787\n","loss/total -0.04126083105802536\n","loss/total 0.6473327279090881\n","loss/total 0.06314851343631744\n","loss/total -0.02787676453590393\n","loss/total -0.24061690270900726\n","loss/total -0.13410769402980804\n","loss/total -0.5201742053031921\n","loss/total 0.05790098011493683\n","loss/total -0.1524285525083542\n","loss/total 0.1444437950849533\n","loss/total 0.25250452756881714\n","loss/total -0.4113174378871918\n","loss/total -0.5645297765731812\n","loss/total 0.4616454243659973\n","loss/total 0.07410016655921936\n","loss/total 0.17912952601909637\n","loss/total -0.4611281156539917\n","loss/total -0.27611252665519714\n","loss/total 0.19024445116519928\n","loss/total 0.1485501527786255\n","loss/total -0.26994839310646057\n","loss/total -0.08553891628980637\n","loss/total 0.5509366393089294\n","loss/total -0.6698222160339355\n","loss/total -0.3030424416065216\n","loss/total -0.06468746066093445\n","loss/total -0.20683646202087402\n","mini-batch training finished\n","loss/total -0.5923154950141907\n","loss/total 0.180257648229599\n","loss/total 0.5678921937942505\n","loss/total -0.02113201469182968\n","loss/total 0.15308305621147156\n","loss/total 0.21518433094024658\n","loss/total -0.3151814043521881\n","loss/total 0.32915180921554565\n","loss/total 0.4734117388725281\n","loss/total -0.08741454035043716\n","loss/total 0.27216118574142456\n","loss/total 0.2866460680961609\n","loss/total 0.42004069685935974\n","loss/total -0.6484870314598083\n","loss/total -0.9711293578147888\n","loss/total -0.21555927395820618\n","loss/total 0.12568598985671997\n","loss/total -0.8908524513244629\n","loss/total -0.618181586265564\n","loss/total 0.13823476433753967\n","loss/total 0.24591071903705597\n","loss/total -0.27104389667510986\n","loss/total 0.328492671251297\n","loss/total 0.34642747044563293\n","loss/total -0.11153822392225266\n","loss/total -0.427122563123703\n","loss/total -0.02023468166589737\n","loss/total 0.32172122597694397\n","loss/total -0.32689589262008667\n","loss/total 0.0933947041630745\n","loss/total -0.01197274774312973\n","loss/total -0.3347965478897095\n","mini-batch training finished\n","loss/total -0.17381709814071655\n","loss/total 1.4229851961135864\n","loss/total -0.025135133415460587\n","loss/total -0.0968615710735321\n","loss/total 0.11719067394733429\n","loss/total -0.05124281346797943\n","loss/total 0.0520695298910141\n","loss/total 0.6654307842254639\n","loss/total 0.16662785410881042\n","loss/total -0.3583275079727173\n","loss/total 0.5217423439025879\n","loss/total 0.12362805008888245\n","loss/total -0.14671176671981812\n","loss/total 0.5280178189277649\n","loss/total 0.4211423397064209\n","loss/total -0.04962555319070816\n","loss/total 0.350751131772995\n","loss/total 0.03747610002756119\n","loss/total 0.1367073804140091\n","loss/total 0.45054101943969727\n","loss/total -0.22505971789360046\n","loss/total -0.28722527623176575\n","loss/total -0.08944190293550491\n","loss/total 0.41111546754837036\n","loss/total -0.6056625247001648\n","loss/total 0.14965608716011047\n","loss/total -0.41436880826950073\n","loss/total -0.005613759160041809\n","loss/total 0.08671286702156067\n","loss/total 0.8978042602539062\n","loss/total 0.5183056592941284\n","loss/total 0.10853887349367142\n","mini-batch training finished\n","loss/total 0.3731442093849182\n","loss/total 0.23867732286453247\n","loss/total -0.3411666452884674\n","loss/total -0.23092567920684814\n","loss/total 0.2124456763267517\n","loss/total 0.38258159160614014\n","loss/total 0.07188352942466736\n","loss/total -0.356232225894928\n","loss/total -0.741087019443512\n","loss/total -0.28009331226348877\n","loss/total 0.30462872982025146\n","loss/total -0.2680143415927887\n","loss/total -0.13372129201889038\n","loss/total 0.10258682072162628\n","loss/total 0.4129044711589813\n","loss/total 0.06771562248468399\n","loss/total -0.3765413165092468\n","loss/total -0.1269235759973526\n","loss/total 0.5957311987876892\n","loss/total -0.3161243796348572\n","loss/total -0.15985670685768127\n","loss/total -0.41597792506217957\n","loss/total -0.22689786553382874\n","loss/total 0.07263925671577454\n","loss/total -0.38665828108787537\n","loss/total -0.2949141263961792\n","loss/total -0.9137350916862488\n","loss/total 0.273286372423172\n","loss/total 0.7953341007232666\n","loss/total -0.013022586703300476\n","loss/total -0.3010280430316925\n","loss/total -0.05951876565814018\n","mini-batch training finished\n","loss/total 0.09864836931228638\n","loss/total 0.6411543488502502\n","loss/total 0.22083154320716858\n","loss/total -0.0013224519789218903\n","loss/total 0.31981977820396423\n","loss/total 0.1733245849609375\n","loss/total 0.9693254232406616\n","loss/total -0.8920340538024902\n","loss/total 0.13831494748592377\n","loss/total 0.396585613489151\n","loss/total 0.2097349762916565\n","loss/total 0.2937752604484558\n","loss/total 0.2345905900001526\n","loss/total 0.2869621515274048\n","loss/total -0.7438132166862488\n","loss/total -0.23349669575691223\n","loss/total 0.2808831036090851\n","loss/total -0.11857737600803375\n","loss/total -0.41224080324172974\n","loss/total 0.08458071202039719\n","loss/total 0.2821347117424011\n","loss/total 0.007922358810901642\n","loss/total 0.5817959308624268\n","loss/total -0.004320904612541199\n","loss/total -0.009832151234149933\n","loss/total -0.5270733833312988\n","loss/total -0.563241720199585\n","loss/total 0.38160067796707153\n","loss/total -0.12207286804914474\n","loss/total 0.3489377498626709\n","loss/total 0.5416495203971863\n","loss/total 0.12894028425216675\n","mini-batch training finished\n","loss/total -0.3664219081401825\n","loss/total -0.5018320083618164\n","loss/total -0.3760843276977539\n","loss/total 0.003163062036037445\n","loss/total 0.14190427958965302\n","loss/total -0.10468550771474838\n","loss/total -0.2818121910095215\n","loss/total 0.21746397018432617\n","loss/total 0.5270398855209351\n","loss/total -0.41235771775245667\n","loss/total -0.6381027698516846\n","loss/total -0.31261205673217773\n","loss/total 0.13257960975170135\n","loss/total -0.6331148147583008\n","loss/total -0.34394019842147827\n","loss/total -0.43415892124176025\n","loss/total -0.4039718806743622\n","loss/total 0.31202417612075806\n","loss/total 0.12891922891139984\n","loss/total -0.4331902861595154\n","loss/total -0.8941819071769714\n","loss/total -0.5013018846511841\n","loss/total -0.6131592392921448\n","loss/total -0.13579201698303223\n","loss/total -0.1283721923828125\n","loss/total -0.7993584275245667\n","loss/total -0.12541761994361877\n","loss/total -0.016859963536262512\n","loss/total -0.25958216190338135\n","loss/total 0.07327906787395477\n","loss/total -0.6211723685264587\n","loss/total -0.8133239150047302\n","mini-batch training finished\n","loss/total 0.46689969301223755\n","loss/total 0.4889702796936035\n","loss/total 0.07575632631778717\n","loss/total 0.7922096252441406\n","loss/total 0.40121152997016907\n","loss/total -0.05089806765317917\n","loss/total -0.2051849663257599\n","loss/total -0.4038102924823761\n","loss/total 0.3782345652580261\n","loss/total 0.06987226754426956\n","loss/total 0.13661013543605804\n","loss/total 0.44346487522125244\n","loss/total -0.2623943090438843\n","loss/total 0.11680758744478226\n","loss/total -0.1890733689069748\n","loss/total 0.06328825652599335\n","loss/total 0.4206157922744751\n","loss/total -0.05936432629823685\n","loss/total 0.019135504961013794\n","loss/total 0.2572808265686035\n","loss/total -0.21379795670509338\n","loss/total -0.213161900639534\n","loss/total 0.27373358607292175\n","loss/total 0.04562021791934967\n","loss/total 0.0011772587895393372\n","loss/total -0.6972247362136841\n","loss/total -0.07229273021221161\n","loss/total 0.1443517506122589\n","loss/total 0.11471667885780334\n","loss/total -0.08532996475696564\n","loss/total 0.670245885848999\n","loss/total -0.0010458678007125854\n","mini-batch training finished\n","loss/total -0.1560385674238205\n","loss/total 0.39550551772117615\n","loss/total 0.22993478178977966\n","loss/total -0.4934236705303192\n","loss/total 0.5248270630836487\n","loss/total 0.2957283556461334\n","loss/total 0.313350111246109\n","loss/total -0.03145385533571243\n","loss/total 0.02156510204076767\n","loss/total 0.18582242727279663\n","loss/total -0.19241181015968323\n","loss/total 0.18117937445640564\n","loss/total 0.39169010519981384\n","loss/total -0.003741346299648285\n","loss/total -0.12321939319372177\n","loss/total -0.2379884272813797\n","loss/total -0.046232279390096664\n","loss/total -0.2013360857963562\n","loss/total 0.22267207503318787\n","loss/total -0.5660852193832397\n","loss/total 0.2076697051525116\n","loss/total -0.10708742588758469\n","loss/total 0.3666123151779175\n","loss/total 0.12524119019508362\n","loss/total 0.1802600473165512\n","loss/total -0.12775233387947083\n","loss/total -0.4708653688430786\n","loss/total -0.16922545433044434\n","loss/total -0.12803253531455994\n","loss/total 0.4952492117881775\n","loss/total -0.20662948489189148\n","loss/total 0.3589535355567932\n","mini-batch training finished\n","loss/total 0.7268590927124023\n","loss/total 0.14520218968391418\n","loss/total 0.09309019148349762\n","loss/total 0.39467760920524597\n","loss/total 0.2480984330177307\n","loss/total 0.2834246754646301\n","loss/total 0.2525045871734619\n","loss/total -0.2872549593448639\n","loss/total 0.2119385302066803\n","loss/total -0.16922453045845032\n","loss/total -0.1727052628993988\n","loss/total 0.7301270961761475\n","loss/total 0.6230583190917969\n","loss/total 0.1667555272579193\n","loss/total -0.1734611690044403\n","loss/total 0.07346149533987045\n","loss/total 0.13108950853347778\n","loss/total -0.22576391696929932\n","loss/total 0.19118312001228333\n","loss/total 0.4794926643371582\n","loss/total -0.12344641983509064\n","loss/total 0.049953680485486984\n","loss/total -0.15558820962905884\n","loss/total 0.606253445148468\n","loss/total 0.31446173787117004\n","loss/total 0.24329549074172974\n","loss/total -0.04889995604753494\n","loss/total 0.1064293384552002\n","loss/total 0.01981867104768753\n","loss/total -0.004119563847780228\n","loss/total -0.13017767667770386\n","loss/total 0.13931435346603394\n","mini-batch training finished\n","loss/total -0.6016924977302551\n","loss/total -0.3683358132839203\n","loss/total 0.9680753946304321\n","loss/total -0.5450164675712585\n","loss/total 0.18852072954177856\n","loss/total 0.5043845772743225\n","loss/total 0.4580906331539154\n","loss/total -0.05654425173997879\n","loss/total 0.24277061223983765\n","loss/total 0.6464551687240601\n","loss/total 0.06863050907850266\n","loss/total 0.27330029010772705\n","loss/total -0.8725638389587402\n","loss/total -0.7113742232322693\n","loss/total -0.12589329481124878\n","loss/total 0.2063654512166977\n","loss/total -0.34992411732673645\n","loss/total 0.5304762125015259\n","loss/total 0.14571020007133484\n","loss/total -0.10415083914995193\n","loss/total -1.0291612148284912\n","loss/total -0.3452509045600891\n","loss/total 0.23658466339111328\n","loss/total 0.3281198740005493\n","loss/total -0.1776048243045807\n","loss/total 0.14109349250793457\n","loss/total 0.8285387754440308\n","loss/total -0.5152679681777954\n","loss/total 0.16149288415908813\n","loss/total -0.7262094616889954\n","loss/total -0.41401124000549316\n","loss/total 0.15490034222602844\n","mini-batch training finished\n","loss/total -0.07179665565490723\n","loss/total 0.08827894926071167\n","loss/total 0.3087737560272217\n","loss/total -0.09907156229019165\n","loss/total 0.004860617220401764\n","loss/total -0.07393354177474976\n","loss/total -0.2659122943878174\n","loss/total -0.006181672215461731\n","loss/total -0.1508525162935257\n","loss/total 0.013787303119897842\n","loss/total -0.3434358835220337\n","loss/total -0.5871046781539917\n","loss/total 0.05783350393176079\n","loss/total 0.22080948948860168\n","loss/total -0.37049248814582825\n","loss/total -0.013014659285545349\n","loss/total -0.11358264833688736\n","loss/total -0.18206080794334412\n","loss/total -0.0962366983294487\n","loss/total 0.002529360353946686\n","loss/total -0.4735148847103119\n","loss/total -0.15742896497249603\n","loss/total -0.05266605317592621\n","loss/total -0.16943612694740295\n","loss/total -0.1915019154548645\n","loss/total 0.036867961287498474\n","loss/total -0.6587470173835754\n","loss/total 0.040871456265449524\n","loss/total -0.3859754204750061\n","loss/total -0.3404291570186615\n","loss/total 0.033532604575157166\n","loss/total -0.02568092942237854\n","mini-batch training finished\n","loss/total -0.1984010636806488\n","loss/total 0.06008542329072952\n","loss/total 0.27786895632743835\n","loss/total 0.513239860534668\n","loss/total 0.42342594265937805\n","loss/total 0.6162353754043579\n","loss/total 0.37112438678741455\n","loss/total 0.18820619583129883\n","loss/total -0.30171075463294983\n","loss/total 0.5740155577659607\n","loss/total 0.4834609031677246\n","loss/total 0.562796950340271\n","loss/total -0.43892329931259155\n","loss/total 0.28891411423683167\n","loss/total -0.10699321329593658\n","loss/total 0.27606454491615295\n","loss/total -0.4845955967903137\n","loss/total 0.20753930509090424\n","loss/total 0.02976815775036812\n","loss/total 0.8614614605903625\n","loss/total 0.24131491780281067\n","loss/total 0.050639405846595764\n","loss/total -0.3260428309440613\n","loss/total 0.2907932996749878\n","loss/total -0.010196186602115631\n","loss/total -0.01952027529478073\n","loss/total 0.22585028409957886\n","loss/total 0.4020203948020935\n","loss/total 0.6301119923591614\n","loss/total -0.25251221656799316\n","loss/total 0.4510086476802826\n","loss/total -0.30089014768600464\n","mini-batch training finished\n","loss/total -0.5260832905769348\n","loss/total 0.23426252603530884\n","loss/total 0.08526580780744553\n","loss/total -0.004215933382511139\n","loss/total 0.2971618175506592\n","loss/total -0.9649507403373718\n","loss/total -0.5867777466773987\n","loss/total 0.31841331720352173\n","loss/total -0.4945010244846344\n","loss/total 0.15718188881874084\n","loss/total 0.05894969403743744\n","loss/total -0.47608017921447754\n","loss/total -0.5292348861694336\n","loss/total -0.3833741545677185\n","loss/total -0.7808505892753601\n","loss/total 0.4145459532737732\n","loss/total -0.4282267093658447\n","loss/total -0.13143108785152435\n","loss/total -0.11784527450799942\n","loss/total 0.22346708178520203\n","loss/total -0.28908178210258484\n","loss/total -0.7717866897583008\n","loss/total -0.7724561095237732\n","loss/total 0.13338415324687958\n","loss/total -0.7777832746505737\n","loss/total -0.530640184879303\n","loss/total -0.29322630167007446\n","loss/total -0.36377477645874023\n","loss/total -0.5879389047622681\n","loss/total 0.4714353680610657\n","loss/total 0.23415367305278778\n","loss/total -0.4552057385444641\n","mini-batch training finished\n","loss/total 0.13312357664108276\n","loss/total 0.06710641086101532\n","loss/total 0.7561110258102417\n","loss/total 1.4502445459365845\n","loss/total 0.1595766246318817\n","loss/total 0.024275701493024826\n","loss/total 0.6377614140510559\n","loss/total -0.1772640347480774\n","loss/total -0.38083603978157043\n","loss/total 0.1566140353679657\n","loss/total -0.2690321207046509\n","loss/total 0.981859564781189\n","loss/total -0.2642752230167389\n","loss/total 0.48042747378349304\n","loss/total 0.3613640069961548\n","loss/total 0.5799621343612671\n","loss/total 0.5767479538917542\n","loss/total 0.2001725137233734\n","loss/total 0.2139894664287567\n","loss/total 0.2257602959871292\n","loss/total -0.01642424613237381\n","loss/total 0.329263836145401\n","loss/total 0.11728625744581223\n","loss/total 0.007401026785373688\n","loss/total 0.9966840744018555\n","loss/total -0.09728758037090302\n","loss/total -0.14609476923942566\n","loss/total 0.1951380968093872\n","loss/total -0.15488629043102264\n","loss/total 0.3005722761154175\n","loss/total 0.30893394351005554\n","loss/total 0.22093410789966583\n","mini-batch training finished\n","loss/total -0.2697995603084564\n","loss/total -0.3026825189590454\n","loss/total -0.5569918751716614\n","loss/total 1.196351170539856\n","loss/total 0.15660595893859863\n","loss/total -0.14610567688941956\n","loss/total -0.3425448536872864\n","loss/total 0.1142733097076416\n","loss/total 0.29286882281303406\n","loss/total -0.6213732957839966\n","loss/total 0.8910486102104187\n","loss/total -0.7083086967468262\n","loss/total -0.12449319660663605\n","loss/total -0.48497653007507324\n","loss/total -0.6031486988067627\n","loss/total 0.32164064049720764\n","loss/total 0.1912141740322113\n","loss/total -0.35438716411590576\n","loss/total 0.366869181394577\n","loss/total -0.42224588990211487\n","loss/total -0.36560961604118347\n","loss/total 0.3818809986114502\n","loss/total -0.5522713661193848\n","loss/total -0.3730109930038452\n","loss/total 0.0015374571084976196\n","loss/total 0.04392198473215103\n","loss/total -0.582308292388916\n","loss/total 0.18887698650360107\n","loss/total -0.6413449048995972\n","loss/total 0.07142499089241028\n","loss/total -0.6326513886451721\n","loss/total 0.2852781414985657\n","mini-batch training finished\n","loss/total -0.11740638315677643\n","loss/total 0.20610791444778442\n","loss/total 0.555088222026825\n","loss/total -0.2638545036315918\n","loss/total 0.18191558122634888\n","loss/total 0.2914941906929016\n","loss/total 0.4500601589679718\n","loss/total 0.14034788310527802\n","loss/total 0.9603884816169739\n","loss/total -0.42503923177719116\n","loss/total 0.14246627688407898\n","loss/total -0.10834244638681412\n","loss/total 0.29496315121650696\n","loss/total -0.49631667137145996\n","loss/total 0.07276120781898499\n","loss/total 0.14138706028461456\n","loss/total 0.3860354721546173\n","loss/total -0.20530283451080322\n","loss/total -0.07452971488237381\n","loss/total -0.3327450752258301\n","loss/total -0.11388903111219406\n","loss/total -0.32157695293426514\n","loss/total 0.520386278629303\n","loss/total 0.2222355306148529\n","loss/total 0.24723610281944275\n","loss/total 0.09410084038972855\n","loss/total -0.4690482020378113\n","loss/total 0.29620611667633057\n","loss/total 0.18798258900642395\n","loss/total -0.22313964366912842\n","loss/total 0.5048558712005615\n","loss/total -0.33385732769966125\n","mini-batch training finished\n","loss/total 0.013884952291846275\n","loss/total 0.19361050426959991\n","loss/total -0.3389131724834442\n","loss/total -0.33454573154449463\n","loss/total -0.20156709849834442\n","loss/total -0.0008942335844039917\n","loss/total 0.15697097778320312\n","loss/total 0.6662647724151611\n","loss/total -0.2333892583847046\n","loss/total -0.13762396574020386\n","loss/total 0.30052870512008667\n","loss/total -0.10222922265529633\n","loss/total 0.33977556228637695\n","loss/total -0.009415209293365479\n","loss/total -0.7444353699684143\n","loss/total -0.1862531453371048\n","loss/total 0.21927866339683533\n","loss/total 0.09553046524524689\n","loss/total -0.13188114762306213\n","loss/total 0.013952650129795074\n","loss/total -0.8899103999137878\n","loss/total 0.17731228470802307\n","loss/total -0.013529375195503235\n","loss/total -0.8217341899871826\n","loss/total 0.14940202236175537\n","loss/total -0.49377626180648804\n","loss/total 0.04534627124667168\n","loss/total -0.1361425817012787\n","loss/total 0.370375394821167\n","loss/total -0.8075740337371826\n","loss/total -0.24894177913665771\n","loss/total -0.20581917464733124\n","mini-batch training finished\n","loss/total 0.2613905668258667\n","loss/total -0.24222110211849213\n","loss/total -0.009156808257102966\n","loss/total 0.012720048427581787\n","loss/total -0.40454038977622986\n","loss/total 0.49870914220809937\n","loss/total 0.07126250863075256\n","loss/total 0.28054511547088623\n","loss/total -0.07469327002763748\n","loss/total 0.07591177523136139\n","loss/total -0.37228283286094666\n","loss/total -0.32481205463409424\n","loss/total -0.015126585960388184\n","loss/total 0.04727088660001755\n","loss/total -0.1064746305346489\n","loss/total 0.1756223887205124\n","loss/total 0.1897687315940857\n","loss/total -0.4037681818008423\n","loss/total -0.5924908518791199\n","loss/total 0.11763244867324829\n","loss/total -0.5136840343475342\n","loss/total -0.009244956076145172\n","loss/total -0.13451826572418213\n","loss/total 0.5357754230499268\n","loss/total 0.14324374496936798\n","loss/total -0.16268785297870636\n","loss/total -0.2651994526386261\n","loss/total -0.46709898114204407\n","loss/total -0.5183563232421875\n","loss/total -0.003663673996925354\n","loss/total -0.09795568138360977\n","loss/total 0.33582454919815063\n","mini-batch training finished\n","loss/total 0.2717249393463135\n","loss/total -0.21468859910964966\n","loss/total -0.3524283468723297\n","loss/total 0.6566131114959717\n","loss/total -0.5690447688102722\n","loss/total 0.6035661697387695\n","loss/total 0.2635144293308258\n","loss/total 0.29506656527519226\n","loss/total -0.5009111166000366\n","loss/total -0.3713011145591736\n","loss/total 0.28645873069763184\n","loss/total 0.11774852871894836\n","loss/total 0.433180570602417\n","loss/total 0.04479329288005829\n","loss/total -0.2719425857067108\n","loss/total 0.31111910939216614\n","loss/total -0.044922057539224625\n","loss/total -0.1438060700893402\n","loss/total 0.2888706922531128\n","loss/total -0.3947446942329407\n","loss/total 0.011563897132873535\n","loss/total -0.27058884501457214\n","loss/total 0.6847195625305176\n","loss/total -0.20202073454856873\n","loss/total -0.4717180132865906\n","loss/total 0.4174448847770691\n","loss/total -0.16763447225093842\n","loss/total -0.3753196597099304\n","loss/total -0.41085198521614075\n","loss/total 0.5851033926010132\n","loss/total 0.10951921343803406\n","loss/total 0.007638322189450264\n","mini-batch training finished\n","loss/total -0.06965178996324539\n","loss/total 0.30665186047554016\n","loss/total 0.07217655330896378\n","loss/total 0.4816255271434784\n","loss/total 0.25934162735939026\n","loss/total 0.2126253843307495\n","loss/total 0.19172611832618713\n","loss/total 0.48494306206703186\n","loss/total 0.07357678562402725\n","loss/total 0.2600100040435791\n","loss/total 0.12422584742307663\n","loss/total 0.038234394043684006\n","loss/total 0.2739940583705902\n","loss/total -0.46275046467781067\n","loss/total 0.2992376685142517\n","loss/total 0.4080645740032196\n","loss/total -0.045875176787376404\n","loss/total 0.4000963866710663\n","loss/total -0.10004651546478271\n","loss/total 0.03609810769557953\n","loss/total 0.3251645565032959\n","loss/total 0.36612677574157715\n","loss/total -0.09183773398399353\n","loss/total -0.03707430139183998\n","loss/total -0.5448666214942932\n","loss/total 0.3780100643634796\n","loss/total 0.308569997549057\n","loss/total 0.661936342716217\n","loss/total 0.09541294723749161\n","loss/total -0.5853778719902039\n","loss/total -0.11834648996591568\n","loss/total 0.36448249220848083\n","mini-batch training finished\n","loss/total -0.18053260445594788\n","loss/total 0.646799623966217\n","loss/total -0.2122342884540558\n","loss/total 0.2842262387275696\n","loss/total -0.14334462583065033\n","loss/total 0.10152232646942139\n","loss/total 0.05330878496170044\n","loss/total 0.42532703280448914\n","loss/total -0.3044925332069397\n","loss/total -0.017730634659528732\n","loss/total 0.7125290632247925\n","loss/total 0.13310745358467102\n","loss/total -0.19663608074188232\n","loss/total -0.3831465244293213\n","loss/total -0.15219053626060486\n","loss/total 0.18254485726356506\n","loss/total 0.06683791428804398\n","loss/total 0.25016796588897705\n","loss/total -0.20499563217163086\n","loss/total 0.5329092741012573\n","loss/total 0.01718294620513916\n","loss/total 0.40624433755874634\n","loss/total -0.7639105916023254\n","loss/total -0.4176388680934906\n","loss/total 0.11742289364337921\n","loss/total 0.42753225564956665\n","loss/total 0.1514073759317398\n","loss/total -0.22347164154052734\n","loss/total 0.08369675278663635\n","loss/total -0.25901857018470764\n","loss/total -0.4106220006942749\n","loss/total -0.08921504020690918\n","mini-batch training finished\n","loss/total -0.037555404007434845\n","loss/total -0.29869553446769714\n","loss/total 0.12672866880893707\n","loss/total -0.4175858497619629\n","loss/total 0.7608931660652161\n","loss/total 0.019106876105070114\n","loss/total 0.32948988676071167\n","loss/total 0.48132985830307007\n","loss/total -0.10378381609916687\n","loss/total -0.339049756526947\n","loss/total -0.3021067678928375\n","loss/total 0.2102920413017273\n","loss/total 0.269866406917572\n","loss/total 0.21721424162387848\n","loss/total 0.02423730492591858\n","loss/total 0.3646348714828491\n","loss/total 0.49859803915023804\n","loss/total 0.12192206084728241\n","loss/total -0.2312822788953781\n","loss/total -0.28559979796409607\n","loss/total -0.44366320967674255\n","loss/total 0.5542628765106201\n","loss/total -0.12375306338071823\n","loss/total -0.12396900355815887\n","loss/total 0.4442152678966522\n","loss/total -0.5015787482261658\n","loss/total -0.43800702691078186\n","loss/total 0.2224244773387909\n","loss/total -0.6077448725700378\n","loss/total 0.3971899747848511\n","loss/total 0.5256766080856323\n","loss/total -0.36975425481796265\n","mini-batch training finished\n","loss/total -0.3884899616241455\n","loss/total 0.30659210681915283\n","loss/total 0.7594689130783081\n","loss/total 0.3533881604671478\n","loss/total -0.29056334495544434\n","loss/total 0.4691966772079468\n","loss/total 0.038305096328258514\n","loss/total -0.13636414706707\n","loss/total -0.257213830947876\n","loss/total 0.4041459858417511\n","loss/total 0.2500598132610321\n","loss/total 0.4181712865829468\n","loss/total -0.23387452960014343\n","loss/total 0.506110429763794\n","loss/total -0.405128538608551\n","loss/total -0.0739828497171402\n","loss/total -0.18105489015579224\n","loss/total -0.6399916410446167\n","loss/total -0.05898895114660263\n","loss/total 0.2604996860027313\n","loss/total -0.45381441712379456\n","loss/total 0.19381600618362427\n","loss/total 0.9060556888580322\n","loss/total -0.068230040371418\n","loss/total 0.06932900846004486\n","loss/total 0.9737762212753296\n","loss/total -0.31996721029281616\n","loss/total -0.046061109751462936\n","loss/total -0.2538522481918335\n","loss/total 0.3481784164905548\n","loss/total -0.5440505743026733\n","loss/total -0.16922390460968018\n","mini-batch training finished\n","loss/total 0.5185995697975159\n","loss/total 0.0056858547031879425\n","loss/total -0.30759868025779724\n","loss/total 0.6883454322814941\n","loss/total -0.32072514295578003\n","loss/total 0.0035672150552272797\n","loss/total -0.15595749020576477\n","loss/total -0.06811486929655075\n","loss/total 0.3860408067703247\n","loss/total -0.37956076860427856\n","loss/total 0.09779873490333557\n","loss/total -0.29882973432540894\n","loss/total -0.08657001703977585\n","loss/total -0.06526342779397964\n","loss/total 0.2106381058692932\n","loss/total -0.42490214109420776\n","loss/total -0.09391790628433228\n","loss/total -0.47533679008483887\n","loss/total 0.06234016641974449\n","loss/total -0.24625970423221588\n","loss/total 0.01482507586479187\n","loss/total 0.047742798924446106\n","loss/total 0.20912551879882812\n","loss/total -0.2755467891693115\n","loss/total -0.6780924797058105\n","loss/total 0.19456467032432556\n","loss/total 0.19465985894203186\n","loss/total 0.13881638646125793\n","loss/total -0.19191491603851318\n","loss/total -0.8024484515190125\n","loss/total 0.45911070704460144\n","loss/total -0.3371598720550537\n","mini-batch training finished\n","loss/total -0.4608207643032074\n","loss/total 0.43607020378112793\n","loss/total 0.15721549093723297\n","loss/total -0.04295807331800461\n","loss/total -0.07786403596401215\n","loss/total 0.1956539750099182\n","loss/total -0.3365655243396759\n","loss/total -0.40275639295578003\n","loss/total -0.4491615295410156\n","loss/total 0.3983515202999115\n","loss/total -0.0855737179517746\n","loss/total -0.4299168288707733\n","loss/total 0.22610993683338165\n","loss/total -0.2866394817829132\n","loss/total -0.21913030743598938\n","loss/total -0.46737486124038696\n","loss/total 0.15243114531040192\n","loss/total 0.09086670726537704\n","loss/total -0.13956908881664276\n","loss/total -0.37252283096313477\n","loss/total -0.3493883013725281\n","loss/total -0.3722449839115143\n","loss/total 0.012678764760494232\n","loss/total -0.5721665620803833\n","loss/total 0.2234070599079132\n","loss/total 0.3058609068393707\n","loss/total -0.3723374605178833\n","loss/total -0.5941289067268372\n","loss/total -0.5652168393135071\n","loss/total -0.7009061574935913\n","loss/total -0.04372106492519379\n","loss/total 0.12098132073879242\n","mini-batch training finished\n","loss/total 0.0037401020526885986\n","loss/total 0.04871790111064911\n","loss/total 0.3478049039840698\n","loss/total -0.025079764425754547\n","loss/total 0.5628254413604736\n","loss/total -0.09858627617359161\n","loss/total 0.1796354055404663\n","loss/total 0.7256473898887634\n","loss/total -0.15832611918449402\n","loss/total 0.47445058822631836\n","loss/total -0.08203239738941193\n","loss/total 0.008737847208976746\n","loss/total 0.4886007010936737\n","loss/total 0.7955557703971863\n","loss/total -0.35309720039367676\n","loss/total -0.17870080471038818\n","loss/total -0.3964214324951172\n","loss/total 0.45087647438049316\n","loss/total -0.22506022453308105\n","loss/total 0.4270627796649933\n","loss/total 0.15197023749351501\n","loss/total 0.4200908839702606\n","loss/total -0.08753976225852966\n","loss/total 0.032461412250995636\n","loss/total 0.632908284664154\n","loss/total -0.1515253335237503\n","loss/total 0.03006996586918831\n","loss/total -0.03565891832113266\n","loss/total -0.03614134341478348\n","loss/total -0.06340613961219788\n","loss/total 0.244510680437088\n","loss/total 0.07922255992889404\n","mini-batch training finished\n","loss/total -0.462030291557312\n","loss/total 0.2714489996433258\n","loss/total 0.49343496561050415\n","loss/total 0.14424243569374084\n","loss/total 0.08231626451015472\n","loss/total -0.021934140473604202\n","loss/total 0.2830643057823181\n","loss/total 0.16695739328861237\n","loss/total -0.09881353378295898\n","loss/total 0.6476758718490601\n","loss/total -0.0945148840546608\n","loss/total 0.150055930018425\n","loss/total 0.14420761168003082\n","loss/total -0.33483850955963135\n","loss/total -0.07421920448541641\n","loss/total -0.31944116950035095\n","loss/total 0.1042921245098114\n","loss/total -0.24726063013076782\n","loss/total -0.0674063190817833\n","loss/total 0.009215079247951508\n","loss/total -0.23592399060726166\n","loss/total 0.26161015033721924\n","loss/total 0.02800459787249565\n","loss/total -0.0019035637378692627\n","loss/total 0.2753666639328003\n","loss/total -0.32440608739852905\n","loss/total -0.6613531112670898\n","loss/total -0.08475306630134583\n","loss/total 0.45732998847961426\n","loss/total -0.3060035705566406\n","loss/total 0.373081237077713\n","loss/total -0.20161405205726624\n","mini-batch training finished\n","loss/total -0.09296780079603195\n","loss/total 0.2610112428665161\n","loss/total 0.7462743520736694\n","loss/total -0.4395987391471863\n","loss/total -0.41139841079711914\n","loss/total 0.5647993087768555\n","loss/total -0.16377483308315277\n","loss/total -0.040908657014369965\n","loss/total 0.3684275448322296\n","loss/total -0.36610862612724304\n","loss/total 0.5078854560852051\n","loss/total 0.009267814457416534\n","loss/total -0.655051589012146\n","loss/total -0.2719215154647827\n","loss/total 0.21749576926231384\n","loss/total -0.20037035644054413\n","loss/total 0.2543240189552307\n","loss/total -0.49079790711402893\n","loss/total -0.46683064103126526\n","loss/total 0.13638611137866974\n","loss/total -0.45005905628204346\n","loss/total 0.5286233425140381\n","loss/total -0.2796286344528198\n","loss/total 0.10406388342380524\n","loss/total 0.40550878643989563\n","loss/total -0.2788042724132538\n","loss/total 0.008046798408031464\n","loss/total 0.1069953665137291\n","loss/total 0.3102123737335205\n","loss/total -0.26812830567359924\n","loss/total -0.8378932476043701\n","loss/total -0.4998852610588074\n","mini-batch training finished\n","loss/total 0.5265973210334778\n","loss/total 0.8982385396957397\n","loss/total 0.43917685747146606\n","loss/total -0.1683112382888794\n","loss/total -0.08562879264354706\n","loss/total 0.1948763132095337\n","loss/total 0.17613787949085236\n","loss/total 0.012129910290241241\n","loss/total 0.36385616660118103\n","loss/total 0.1658688187599182\n","loss/total 0.046978771686553955\n","loss/total -0.4048973321914673\n","loss/total 0.011974520981311798\n","loss/total -0.1987125426530838\n","loss/total 0.79349684715271\n","loss/total 0.13981246948242188\n","loss/total -0.13885238766670227\n","loss/total 0.11755776405334473\n","loss/total 0.1758330911397934\n","loss/total -0.11083808541297913\n","loss/total 0.2558642029762268\n","loss/total 0.4428027868270874\n","loss/total 0.1616707742214203\n","loss/total -0.03492475301027298\n","loss/total 0.6086519360542297\n","loss/total -0.39984601736068726\n","loss/total -0.031752802431583405\n","loss/total 0.2998843789100647\n","loss/total 0.7280997633934021\n","loss/total -0.6223825812339783\n","loss/total -0.09639221429824829\n","loss/total 0.2494858205318451\n","mini-batch training finished\n","loss/total -0.1747775822877884\n","loss/total 0.2674504518508911\n","loss/total 0.23193752765655518\n","loss/total -0.3080851137638092\n","loss/total 0.3075328469276428\n","loss/total -0.2297992706298828\n","loss/total 0.2796299457550049\n","loss/total -0.13419726490974426\n","loss/total 0.08371859043836594\n","loss/total 0.07126076519489288\n","loss/total -0.3504672646522522\n","loss/total -0.40167972445487976\n","loss/total 0.43004897236824036\n","loss/total -0.03214147686958313\n","loss/total -0.6999529600143433\n","loss/total 0.26167136430740356\n","loss/total -0.39981549978256226\n","loss/total 0.24358105659484863\n","loss/total -0.09235621243715286\n","loss/total 0.007033459842205048\n","loss/total -0.178608700633049\n","loss/total -0.13337533175945282\n","loss/total -0.1546574831008911\n","loss/total 0.13542869687080383\n","loss/total 0.35378098487854004\n","loss/total -0.42825013399124146\n","loss/total 0.3818010985851288\n","loss/total -0.37607887387275696\n","loss/total -0.15455135703086853\n","loss/total -0.23222778737545013\n","loss/total -0.3389381170272827\n","loss/total -0.03974650800228119\n","mini-batch training finished\n","loss/total -0.4005962014198303\n","loss/total 0.8071528077125549\n","loss/total -0.3297061324119568\n","loss/total -0.20502765476703644\n","loss/total 0.43660062551498413\n","loss/total -0.22832027077674866\n","loss/total -0.11538572609424591\n","loss/total -0.28675976395606995\n","loss/total -0.24848893284797668\n","loss/total -0.24954713881015778\n","loss/total -0.42430973052978516\n","loss/total -0.6737591028213501\n","loss/total 0.9598069787025452\n","loss/total -0.3138439357280731\n","loss/total 0.09978500008583069\n","loss/total -0.6223883628845215\n","loss/total 0.3368876576423645\n","loss/total 0.42068251967430115\n","loss/total -0.6285797357559204\n","loss/total -0.3673296272754669\n","loss/total -0.045192644000053406\n","loss/total -0.16508156061172485\n","loss/total -0.6299309730529785\n","loss/total -0.4847455620765686\n","loss/total -0.5548401474952698\n","loss/total 0.35871344804763794\n","loss/total -0.6131937503814697\n","loss/total -0.22651344537734985\n","loss/total -0.3338351249694824\n","loss/total -0.10283108055591583\n","loss/total -0.4328262209892273\n","loss/total 0.4496460556983948\n","mini-batch training finished\n","loss/total 0.418529212474823\n","loss/total -0.21905478835105896\n","loss/total -0.2537342607975006\n","loss/total 0.29446732997894287\n","loss/total -0.5070059895515442\n","loss/total 0.15409508347511292\n","loss/total 0.43194109201431274\n","loss/total 0.17199070751667023\n","loss/total 0.39701056480407715\n","loss/total -0.6099119186401367\n","loss/total 0.3657461702823639\n","loss/total 0.013264022767543793\n","loss/total -0.5976481437683105\n","loss/total 0.06034824624657631\n","loss/total -0.4223184287548065\n","loss/total 0.3097827434539795\n","loss/total -0.14512166380882263\n","loss/total 0.08374366909265518\n","loss/total 0.2440984696149826\n","loss/total 0.007757052779197693\n","loss/total -0.7194608449935913\n","loss/total 0.5495691299438477\n","loss/total 0.09490135312080383\n","loss/total -0.9323160648345947\n","loss/total 0.24134710431098938\n","loss/total 0.09468071907758713\n","loss/total 0.016734350472688675\n","loss/total 0.002151012420654297\n","loss/total -0.3308992087841034\n","loss/total -0.17290551960468292\n","loss/total 0.04703648388385773\n","loss/total -0.7723854184150696\n","mini-batch training finished\n","loss/total 1.1114128828048706\n","loss/total 0.7140985727310181\n","loss/total 0.03187108039855957\n","loss/total 0.07515066862106323\n","loss/total -0.022506922483444214\n","loss/total -0.19411921501159668\n","loss/total 0.5278688669204712\n","loss/total 0.07499536126852036\n","loss/total -0.2334858775138855\n","loss/total -0.0017893053591251373\n","loss/total 0.8964826464653015\n","loss/total 0.2844369411468506\n","loss/total 0.917432427406311\n","loss/total -0.22733250260353088\n","loss/total -0.381872296333313\n","loss/total 0.01253771036863327\n","loss/total 0.8533810377120972\n","loss/total 0.4985333979129791\n","loss/total -0.29345184564590454\n","loss/total -0.033793702721595764\n","loss/total 0.4032731354236603\n","loss/total -0.05945335701107979\n","loss/total -0.0022642239928245544\n","loss/total -0.16124959290027618\n","loss/total 0.47147104144096375\n","loss/total 0.36252808570861816\n","loss/total -0.37271514534950256\n","loss/total 0.13229992985725403\n","loss/total 0.46770918369293213\n","loss/total -0.12396977096796036\n","loss/total 0.10336565971374512\n","loss/total -0.16866417229175568\n","mini-batch training finished\n","loss/total 0.010626230388879776\n","loss/total -0.27851128578186035\n","loss/total -0.05852556973695755\n","loss/total 0.033247265964746475\n","loss/total 0.1724940538406372\n","loss/total -0.0019095875322818756\n","loss/total 0.35305142402648926\n","loss/total 0.4047962725162506\n","loss/total -0.10521671175956726\n","loss/total -0.8099225163459778\n","loss/total 0.07846061140298843\n","loss/total -0.09721782058477402\n","loss/total 0.10486268997192383\n","loss/total -0.5062580108642578\n","loss/total 0.7618222832679749\n","loss/total 0.025217153131961823\n","loss/total -0.021688546985387802\n","loss/total -0.06035018712282181\n","loss/total -0.18241915106773376\n","loss/total 0.318164199590683\n","loss/total -0.09180063009262085\n","loss/total 0.4312222898006439\n","loss/total -0.2982536852359772\n","loss/total -0.5045537948608398\n","loss/total -0.14101237058639526\n","loss/total 0.14572274684906006\n","loss/total -0.0635126456618309\n","loss/total 0.09006568044424057\n","loss/total -0.3151164948940277\n","loss/total -0.019780606031417847\n","loss/total -0.27622461318969727\n","loss/total -0.14956006407737732\n","mini-batch training finished\n","loss/total -0.4711563289165497\n","loss/total -0.2860763967037201\n","loss/total 0.0032274872064590454\n","loss/total 0.4263610541820526\n","loss/total 0.2967372536659241\n","loss/total -0.0815134197473526\n","loss/total -0.11511681973934174\n","loss/total -0.07075841724872589\n","loss/total -0.05361999571323395\n","loss/total -0.5779185891151428\n","loss/total -0.033079154789447784\n","loss/total -0.3788701891899109\n","loss/total -0.08016758412122726\n","loss/total 0.09567289054393768\n","loss/total 0.13029596209526062\n","loss/total -0.3301627039909363\n","loss/total -0.13834914565086365\n","loss/total -0.0024406760931015015\n","loss/total -0.11342962086200714\n","loss/total 0.09650787711143494\n","loss/total 0.14951395988464355\n","loss/total -0.6047927737236023\n","loss/total -0.3010629117488861\n","loss/total -0.23771819472312927\n","loss/total -0.4895608127117157\n","loss/total -0.17378051578998566\n","loss/total 0.3104809820652008\n","loss/total -0.3047046661376953\n","loss/total -0.4187760651111603\n","loss/total -0.16939309239387512\n","loss/total -0.15183314681053162\n","loss/total 0.014040045440196991\n","mini-batch training finished\n","loss/total 0.6572909951210022\n","loss/total 0.3695661425590515\n","loss/total 0.026061028242111206\n","loss/total -0.2659047245979309\n","loss/total 0.5123041868209839\n","loss/total -0.3992229104042053\n","loss/total 0.3799668848514557\n","loss/total 0.026589006185531616\n","loss/total -0.40909719467163086\n","loss/total 0.3644612431526184\n","loss/total 0.15244708955287933\n","loss/total 0.5169922113418579\n","loss/total -0.4362473785877228\n","loss/total -0.17633599042892456\n","loss/total -0.3631056547164917\n","loss/total 0.5812386870384216\n","loss/total 0.19425460696220398\n","loss/total -0.12215758860111237\n","loss/total -0.18967029452323914\n","loss/total 0.19352081418037415\n","loss/total 0.4200184643268585\n","loss/total 0.1739320158958435\n","loss/total -0.20324775576591492\n","loss/total -0.5625143647193909\n","loss/total 0.32476651668548584\n","loss/total 0.5190598368644714\n","loss/total -0.1663891077041626\n","loss/total -0.3261774182319641\n","loss/total -0.5797742605209351\n","loss/total -0.7103043794631958\n","loss/total 0.6275935173034668\n","loss/total -0.045810725539922714\n","mini-batch training finished\n","loss/total 0.2244461625814438\n","loss/total -0.06782601028680801\n","loss/total 0.05003856122493744\n","loss/total 0.06299149990081787\n","loss/total 0.5044801235198975\n","loss/total -0.4956625699996948\n","loss/total 0.10626053065061569\n","loss/total 0.038400620222091675\n","loss/total 0.15322674810886383\n","loss/total 0.011169962584972382\n","loss/total 0.11845356225967407\n","loss/total 0.05071769654750824\n","loss/total -0.542616605758667\n","loss/total -0.3221232295036316\n","loss/total -0.45335790514945984\n","loss/total 0.6473348736763\n","loss/total 0.13928166031837463\n","loss/total 0.15025876462459564\n","loss/total -0.2604197859764099\n","loss/total -0.2927876114845276\n","loss/total 0.6076149344444275\n","loss/total -0.16632142663002014\n","loss/total -0.15862849354743958\n","loss/total -0.5381702780723572\n","loss/total -0.6659145355224609\n","loss/total 0.3563899099826813\n","loss/total -0.0254993699491024\n","loss/total -0.024677395820617676\n","loss/total -0.09447421133518219\n","loss/total -0.5091172456741333\n","loss/total 0.10094406455755234\n","loss/total 0.12483392655849457\n","mini-batch training finished\n","loss/total 0.07921909540891647\n","loss/total -0.05958038195967674\n","loss/total -0.021471716463565826\n","loss/total 0.1183282881975174\n","loss/total 0.6012318134307861\n","loss/total 0.09422159194946289\n","loss/total -0.15768103301525116\n","loss/total -0.1816827356815338\n","loss/total -0.5521610379219055\n","loss/total 0.5731996297836304\n","loss/total -0.2317831814289093\n","loss/total 0.02053903043270111\n","loss/total 0.45294415950775146\n","loss/total -0.20192338526248932\n","loss/total 0.30945852398872375\n","loss/total -0.5778610110282898\n","loss/total -0.1052207201719284\n","loss/total -0.4221169948577881\n","loss/total -0.019333943724632263\n","loss/total 0.550033688545227\n","loss/total 0.07813620567321777\n","loss/total -0.2826497554779053\n","loss/total -0.6250442862510681\n","loss/total 0.31315523386001587\n","loss/total 0.12252505868673325\n","loss/total 0.3411950469017029\n","loss/total -0.4394901990890503\n","loss/total -0.1292436122894287\n","loss/total -0.1682768017053604\n","loss/total 0.10744631290435791\n","loss/total -0.16645506024360657\n","loss/total 0.00754953920841217\n","mini-batch training finished\n","loss/total 0.49185118079185486\n","loss/total -0.21544824540615082\n","loss/total -0.27567896246910095\n","loss/total 0.5080069899559021\n","loss/total 0.69452303647995\n","loss/total 0.1377243548631668\n","loss/total 0.011370910331606865\n","loss/total -0.17609192430973053\n","loss/total 0.37356746196746826\n","loss/total 0.22155940532684326\n","loss/total -0.5687660574913025\n","loss/total -0.08931900560855865\n","loss/total -0.22258523106575012\n","loss/total 0.41847240924835205\n","loss/total 0.014659181237220764\n","loss/total 0.1935984492301941\n","loss/total 0.23846638202667236\n","loss/total 0.28572702407836914\n","loss/total 0.1835484802722931\n","loss/total -0.20065352320671082\n","loss/total -0.24635905027389526\n","loss/total 0.30156660079956055\n","loss/total -0.11676899343729019\n","loss/total -0.1942032128572464\n","loss/total -0.8041172623634338\n","loss/total 0.6811705827713013\n","loss/total -0.12781217694282532\n","loss/total -0.37339335680007935\n","loss/total 0.28093641996383667\n","loss/total 0.3481560945510864\n","loss/total 0.18915759027004242\n","loss/total -0.273939311504364\n","mini-batch training finished\n","loss/total -0.20039838552474976\n","loss/total 0.19512084126472473\n","loss/total 0.5935510993003845\n","loss/total 0.4850121736526489\n","loss/total 0.1833099126815796\n","loss/total -0.21416421234607697\n","loss/total -0.21497313678264618\n","loss/total -0.5621652603149414\n","loss/total -0.025368988513946533\n","loss/total -0.8257321715354919\n","loss/total -0.44118237495422363\n","loss/total 0.657555878162384\n","loss/total -0.2520407736301422\n","loss/total -0.22241640090942383\n","loss/total 0.9521621465682983\n","loss/total -0.021063275635242462\n","loss/total -0.42030319571495056\n","loss/total -0.020571965724229813\n","loss/total -0.31015515327453613\n","loss/total 0.09671062231063843\n","loss/total 0.5603581070899963\n","loss/total -0.23820842802524567\n","loss/total -0.32400548458099365\n","loss/total 0.17258983850479126\n","loss/total -0.3043121099472046\n","loss/total 0.3413783609867096\n","loss/total 0.06618417799472809\n","loss/total 0.11765311658382416\n","loss/total -0.21828201413154602\n","loss/total -0.48538488149642944\n","loss/total 0.16259707510471344\n","loss/total -0.23199379444122314\n","mini-batch training finished\n","loss/total -0.014469504356384277\n","loss/total -0.24959290027618408\n","loss/total 0.04814719781279564\n","loss/total 0.4890034794807434\n","loss/total 0.4522548317909241\n","loss/total 0.12848088145256042\n","loss/total 0.9805083870887756\n","loss/total 0.27773573994636536\n","loss/total -0.45442259311676025\n","loss/total 0.07239328324794769\n","loss/total 0.13936904072761536\n","loss/total -0.23691558837890625\n","loss/total 0.49629175662994385\n","loss/total 0.18841271102428436\n","loss/total 0.36084985733032227\n","loss/total 0.8256273865699768\n","loss/total 0.40494227409362793\n","loss/total 0.17011632025241852\n","loss/total 0.14899423718452454\n","loss/total -0.37394699454307556\n","loss/total 0.6624138355255127\n","loss/total -0.07800710946321487\n","loss/total -0.13268911838531494\n","loss/total 0.48532232642173767\n","loss/total -0.04141923785209656\n","loss/total 0.41167086362838745\n","loss/total 0.3007783889770508\n","loss/total -0.012748245149850845\n","loss/total -0.2932114005088806\n","loss/total 0.13480228185653687\n","loss/total 0.7150000333786011\n","loss/total -0.19427481293678284\n","mini-batch training finished\n","loss/total 0.07815521955490112\n","loss/total 0.32161155343055725\n","loss/total -0.5174590945243835\n","loss/total -0.377238005399704\n","loss/total 0.7501329779624939\n","loss/total 0.05858933925628662\n","loss/total 0.13105672597885132\n","loss/total -0.5307502746582031\n","loss/total -0.2666310966014862\n","loss/total -0.18965470790863037\n","loss/total 0.25434449315071106\n","loss/total -0.25673678517341614\n","loss/total 0.2723565399646759\n","loss/total -0.4038282334804535\n","loss/total 0.12430603057146072\n","loss/total -0.11130879074335098\n","loss/total 0.47754812240600586\n","loss/total -0.20384036004543304\n","loss/total -0.3316274881362915\n","loss/total 0.08704660087823868\n","loss/total 0.598019003868103\n","loss/total -0.3883780241012573\n","loss/total -0.2587073743343353\n","loss/total -0.5297157168388367\n","loss/total -0.34349146485328674\n","loss/total -0.24012157320976257\n","loss/total -0.44132381677627563\n","loss/total -0.2891106605529785\n","loss/total -0.2769787907600403\n","loss/total 0.0285632461309433\n","loss/total 0.2943568229675293\n","loss/total 0.3800360858440399\n","mini-batch training finished\n","loss/total -0.06061585247516632\n","loss/total 0.10485877841711044\n","loss/total 0.5147846937179565\n","loss/total 0.09931028634309769\n","loss/total 0.03716558590531349\n","loss/total -0.016133300960063934\n","loss/total 0.04046459496021271\n","loss/total 0.36024925112724304\n","loss/total 0.24948078393936157\n","loss/total 0.3051833510398865\n","loss/total -0.2881717085838318\n","loss/total -0.4563746452331543\n","loss/total 0.12050609290599823\n","loss/total -0.2524191737174988\n","loss/total 0.02298884093761444\n","loss/total 0.5681142210960388\n","loss/total 0.27257171273231506\n","loss/total -0.23774453997612\n","loss/total 0.10937075316905975\n","loss/total -0.26979994773864746\n","loss/total 0.23472535610198975\n","loss/total -0.31375300884246826\n","loss/total 0.670946478843689\n","loss/total -0.5262038707733154\n","loss/total -0.30145347118377686\n","loss/total 0.17640304565429688\n","loss/total -0.08317182958126068\n","loss/total -0.2194654941558838\n","loss/total 0.35453104972839355\n","loss/total -0.00678059458732605\n","loss/total -0.0008176937699317932\n","loss/total 0.03575873747467995\n","mini-batch training finished\n","loss/total 0.693091094493866\n","loss/total -0.400807648897171\n","loss/total -0.305009663105011\n","loss/total -0.4692363739013672\n","loss/total 0.1649290919303894\n","loss/total 0.11396956443786621\n","loss/total -0.13580010831356049\n","loss/total 0.062378935515880585\n","loss/total -0.5769414305686951\n","loss/total -0.16277068853378296\n","loss/total 0.17018041014671326\n","loss/total -0.6508583426475525\n","loss/total 0.44178882241249084\n","loss/total -0.306505024433136\n","loss/total -0.09570522606372833\n","loss/total 0.03699226304888725\n","loss/total -0.5417777299880981\n","loss/total -0.19967716932296753\n","loss/total -0.1398678421974182\n","loss/total -0.7156800627708435\n","loss/total 0.2619885504245758\n","loss/total 0.3212394416332245\n","loss/total -0.034243397414684296\n","loss/total -0.4058832824230194\n","loss/total 0.022040143609046936\n","loss/total 0.10650362074375153\n","loss/total -0.014775458723306656\n","loss/total 0.05434810742735863\n","loss/total -0.8202876448631287\n","loss/total 0.22050519287586212\n","loss/total -0.36283373832702637\n","loss/total -0.6635569930076599\n","mini-batch training finished\n","loss/total 0.6642500758171082\n","loss/total 0.2986401319503784\n","loss/total 0.038994207978248596\n","loss/total 0.21192839741706848\n","loss/total 0.2985045313835144\n","loss/total 0.7035194039344788\n","loss/total 0.011599101126194\n","loss/total -0.08348536491394043\n","loss/total 0.31908148527145386\n","loss/total 0.05138766020536423\n","loss/total -0.1872701793909073\n","loss/total 0.07145540416240692\n","loss/total 0.6450908184051514\n","loss/total 0.1865089237689972\n","loss/total 0.35766148567199707\n","loss/total -0.10442077368497849\n","loss/total 0.2256329506635666\n","loss/total 0.18262937664985657\n","loss/total -0.20092476904392242\n","loss/total 0.20663386583328247\n","loss/total 0.7527744770050049\n","loss/total -0.2998533248901367\n","loss/total 0.11637343466281891\n","loss/total 0.11529682576656342\n","loss/total -0.028009168803691864\n","loss/total 0.12847775220870972\n","loss/total -0.1471838355064392\n","loss/total 0.21453100442886353\n","loss/total -0.07707157731056213\n","loss/total -0.07951200753450394\n","loss/total 0.23749038577079773\n","loss/total 0.6504106521606445\n","mini-batch training finished\n","loss/total 0.001547258347272873\n","loss/total 0.10122424364089966\n","loss/total 0.020691199228167534\n","loss/total -0.08220790326595306\n","loss/total 0.7301362156867981\n","loss/total 0.46582019329071045\n","loss/total 0.35298413038253784\n","loss/total -0.2584821581840515\n","loss/total -0.059808358550071716\n","loss/total 0.2895982265472412\n","loss/total -0.3552318811416626\n","loss/total -0.19700494408607483\n","loss/total 0.8328298926353455\n","loss/total -0.4750809073448181\n","loss/total 0.3360954523086548\n","loss/total 0.23331613838672638\n","loss/total 0.5087083578109741\n","loss/total 0.16504620015621185\n","loss/total -0.017017293721437454\n","loss/total -0.0004474148154258728\n","loss/total -0.03139737248420715\n","loss/total -0.6153043508529663\n","loss/total 0.7435212135314941\n","loss/total -0.21633747220039368\n","loss/total -0.25390204787254333\n","loss/total -0.03825750946998596\n","loss/total -0.12390190362930298\n","loss/total 0.11908901482820511\n","loss/total 0.6903868317604065\n","loss/total -0.4322795867919922\n","loss/total 0.1607973873615265\n","loss/total -0.21833957731723785\n","mini-batch training finished\n","loss/total -0.057228174060583115\n","loss/total 0.1727266013622284\n","loss/total 0.4879462718963623\n","loss/total 0.23233219981193542\n","loss/total -0.49848607182502747\n","loss/total 0.11078617721796036\n","loss/total -0.0821046307682991\n","loss/total 0.17945370078086853\n","loss/total -0.2626264691352844\n","loss/total -0.4086431860923767\n","loss/total 0.1507820188999176\n","loss/total -0.0627228245139122\n","loss/total 0.24495774507522583\n","loss/total -0.3137022852897644\n","loss/total -0.004720747470855713\n","loss/total 0.27402985095977783\n","loss/total 0.19032464921474457\n","loss/total 0.14231018722057343\n","loss/total 0.11532849818468094\n","loss/total -0.18912963569164276\n","loss/total -0.7486904859542847\n","loss/total -0.10782168805599213\n","loss/total -0.46858537197113037\n","loss/total 0.2708337903022766\n","loss/total -0.39917635917663574\n","loss/total -0.2894463539123535\n","loss/total -0.36532488465309143\n","loss/total -0.1105368509888649\n","loss/total 0.2376062273979187\n","loss/total 0.20961177349090576\n","loss/total 0.1698637753725052\n","loss/total -0.2293795645236969\n","mini-batch training finished\n","loss/total -0.008169934153556824\n","loss/total -0.17937594652175903\n","loss/total 0.4898644685745239\n","loss/total 0.3842807710170746\n","loss/total -0.22487863898277283\n","loss/total 0.5968300700187683\n","loss/total -0.3734908103942871\n","loss/total 0.08155620098114014\n","loss/total 0.16345945000648499\n","loss/total 0.014410238713026047\n","loss/total 0.49133753776550293\n","loss/total -0.09613114595413208\n","loss/total -0.3761530816555023\n","loss/total -0.3868371248245239\n","loss/total 0.05632491409778595\n","loss/total 0.07658926397562027\n","loss/total -0.7294631004333496\n","loss/total 0.17103254795074463\n","loss/total 0.8773748278617859\n","loss/total -0.2622145414352417\n","loss/total 0.0018208734691143036\n","loss/total 0.11549661308526993\n","loss/total -0.014251522719860077\n","loss/total -0.4213694632053375\n","loss/total -0.07937860488891602\n","loss/total -0.7263587713241577\n","loss/total 0.08519317209720612\n","loss/total -0.6133980751037598\n","loss/total 0.00916263833642006\n","loss/total -0.02781558781862259\n","loss/total 0.22748059034347534\n","loss/total 0.6734346151351929\n","mini-batch training finished\n","loss/total 0.023223239928483963\n","loss/total 0.5715717077255249\n","loss/total -0.1726275086402893\n","loss/total 0.4690118432044983\n","loss/total 0.4585716724395752\n","loss/total -0.1259663701057434\n","loss/total 0.12675172090530396\n","loss/total 0.25862181186676025\n","loss/total -0.40481969714164734\n","loss/total -0.022293761372566223\n","loss/total 0.1118590384721756\n","loss/total 0.16937941312789917\n","loss/total 0.4975983500480652\n","loss/total 0.2279975712299347\n","loss/total 0.3870626389980316\n","loss/total -0.21710017323493958\n","loss/total -0.494254469871521\n","loss/total 0.3957374393939972\n","loss/total 0.14674505591392517\n","loss/total 0.5016863346099854\n","loss/total -0.4585045278072357\n","loss/total 0.24353104829788208\n","loss/total -0.16566239297389984\n","loss/total 0.27081653475761414\n","loss/total 0.016755636781454086\n","loss/total 0.18344178795814514\n","loss/total -0.15813851356506348\n","loss/total 0.18035200238227844\n","loss/total 0.0327942818403244\n","loss/total -0.13375267386436462\n","loss/total 0.17758527398109436\n","loss/total 0.22576892375946045\n","mini-batch training finished\n","loss/total 0.3453636169433594\n","loss/total -0.12069179117679596\n","loss/total 0.21082203090190887\n","loss/total 0.18695852160453796\n","loss/total 0.06459438055753708\n","loss/total -0.3077353835105896\n","loss/total -0.02499496191740036\n","loss/total 0.07237574458122253\n","loss/total -0.05351559817790985\n","loss/total -0.25201666355133057\n","loss/total -0.17952695488929749\n","loss/total -0.26326605677604675\n","loss/total -0.39832860231399536\n","loss/total -0.12118861079216003\n","loss/total 0.5795606970787048\n","loss/total 0.46009591221809387\n","loss/total 0.016517117619514465\n","loss/total 0.1944848895072937\n","loss/total -0.11718053370714188\n","loss/total -0.2588030695915222\n","loss/total -0.4259437918663025\n","loss/total -0.07749404013156891\n","loss/total -0.16815310716629028\n","loss/total 0.23283816874027252\n","loss/total -0.18018236756324768\n","loss/total -0.014562539756298065\n","loss/total -0.30050066113471985\n","loss/total 0.07603397220373154\n","loss/total -0.07437674701213837\n","loss/total 0.058856647461652756\n","loss/total -0.06662581861019135\n","loss/total -0.3422943949699402\n","mini-batch training finished\n","loss/total -0.2824214696884155\n","loss/total 0.2784132957458496\n","loss/total -0.27109649777412415\n","loss/total -0.16306206583976746\n","loss/total -0.3249815106391907\n","loss/total -0.2208549827337265\n","loss/total 0.23891541361808777\n","loss/total 0.27532464265823364\n","loss/total 0.07321862876415253\n","loss/total -0.47125592827796936\n","loss/total -0.3121168315410614\n","loss/total -0.42695391178131104\n","loss/total 0.018482528626918793\n","loss/total 0.5917220115661621\n","loss/total -0.5904377102851868\n","loss/total -0.48524218797683716\n","loss/total -0.8149604797363281\n","loss/total 0.48045235872268677\n","loss/total -0.025855470448732376\n","loss/total -0.2933192551136017\n","loss/total -1.1422908306121826\n","loss/total -0.4981957674026489\n","loss/total 0.5081256628036499\n","loss/total -0.26975685358047485\n","loss/total -0.40079817175865173\n","loss/total -0.6313165426254272\n","loss/total -0.03107394278049469\n","loss/total -0.4961322247982025\n","loss/total -0.7894812226295471\n","loss/total 0.15505047142505646\n","loss/total 0.4700247049331665\n","loss/total -0.2974053621292114\n","mini-batch training finished\n","loss/total 0.21937230229377747\n","loss/total -0.221067875623703\n","loss/total 0.3379688858985901\n","loss/total 0.45128631591796875\n","loss/total 0.2571170926094055\n","loss/total -0.0841425433754921\n","loss/total -0.3674176335334778\n","loss/total -0.18355703353881836\n","loss/total 0.656231164932251\n","loss/total -0.33735260367393494\n","loss/total -0.15012091398239136\n","loss/total -0.39941099286079407\n","loss/total -0.4789491891860962\n","loss/total 0.07146473973989487\n","loss/total 0.027254529297351837\n","loss/total 0.3616328239440918\n","loss/total -0.055602602660655975\n","loss/total -0.08053068816661835\n","loss/total -0.14092102646827698\n","loss/total -0.44726845622062683\n","loss/total -0.05870766565203667\n","loss/total 0.03616867959499359\n","loss/total 0.18730109930038452\n","loss/total -0.07240323722362518\n","loss/total -0.08951109647750854\n","loss/total 0.3495182991027832\n","loss/total -0.43637388944625854\n","loss/total -0.4176872670650482\n","loss/total 0.04165227338671684\n","loss/total 0.005878586322069168\n","loss/total -0.6009129285812378\n","loss/total 0.23146088421344757\n","mini-batch training finished\n","loss/total 0.252162903547287\n","loss/total 0.6762931942939758\n","loss/total 0.7174810171127319\n","loss/total -0.041152507066726685\n","loss/total 0.28462812304496765\n","loss/total 0.11234469711780548\n","loss/total -0.21443894505500793\n","loss/total 0.5187900066375732\n","loss/total 0.833811342716217\n","loss/total -0.3999079763889313\n","loss/total -0.1677117496728897\n","loss/total 0.15313124656677246\n","loss/total 0.054819125682115555\n","loss/total 0.03639186918735504\n","loss/total 0.48370984196662903\n","loss/total 0.489040732383728\n","loss/total -0.008412592113018036\n","loss/total 0.1850522756576538\n","loss/total -0.13442274928092957\n","loss/total 0.2624738812446594\n","loss/total 0.5485248565673828\n","loss/total -0.48519834876060486\n","loss/total 0.5060823559761047\n","loss/total 0.11820738017559052\n","loss/total -0.24048998951911926\n","loss/total 0.39042747020721436\n","loss/total 0.12935101985931396\n","loss/total -0.033861495554447174\n","loss/total 0.5117603540420532\n","loss/total -0.3100188374519348\n","loss/total 0.39053794741630554\n","loss/total 0.10652856528759003\n","mini-batch training finished\n","loss/total -0.14588111639022827\n","loss/total 1.0194276571273804\n","loss/total 0.4868796169757843\n","loss/total 0.09640836715698242\n","loss/total 0.851022481918335\n","loss/total 0.10862146317958832\n","loss/total 0.23445464670658112\n","loss/total -0.00792587548494339\n","loss/total 0.7510000467300415\n","loss/total -0.043931663036346436\n","loss/total 0.4314883351325989\n","loss/total -0.07819622755050659\n","loss/total 0.26759788393974304\n","loss/total 0.5267472267150879\n","loss/total 0.40999943017959595\n","loss/total -0.6307852268218994\n","loss/total 0.27685290575027466\n","loss/total 0.11685964465141296\n","loss/total 0.4963718056678772\n","loss/total 0.2895594835281372\n","loss/total 0.6738501787185669\n","loss/total -0.7993473410606384\n","loss/total -0.3019956648349762\n","loss/total 0.27710357308387756\n","loss/total -0.7685083150863647\n","loss/total 0.12137474119663239\n","loss/total 0.27184614539146423\n","loss/total 0.4749019145965576\n","loss/total 0.7305602431297302\n","loss/total 0.32344046235084534\n","loss/total -0.27485156059265137\n","loss/total 0.23406878113746643\n","mini-batch training finished\n","loss/total -0.017113137990236282\n","loss/total -0.1478055715560913\n","loss/total -0.7363544702529907\n","loss/total -0.4370947480201721\n","loss/total 0.010080285370349884\n","loss/total 0.0394040048122406\n","loss/total -0.02794070541858673\n","loss/total -0.3452901244163513\n","loss/total -0.14632605016231537\n","loss/total -0.3506004214286804\n","loss/total -0.17573386430740356\n","loss/total -0.24007508158683777\n","loss/total -0.6433392763137817\n","loss/total -0.14707253873348236\n","loss/total -0.7994579672813416\n","loss/total -0.05601024627685547\n","loss/total -0.1944543421268463\n","loss/total -1.4152443408966064\n","loss/total 0.04934202507138252\n","loss/total -0.8460768461227417\n","loss/total 0.063494011759758\n","loss/total -0.08828885108232498\n","loss/total -0.5245673656463623\n","loss/total 0.061003319919109344\n","loss/total -0.12777841091156006\n","loss/total -0.3695911169052124\n","loss/total -0.6837639808654785\n","loss/total -0.41821688413619995\n","loss/total -0.2498570680618286\n","loss/total 0.07556406408548355\n","loss/total -0.7983825206756592\n","loss/total -0.28142356872558594\n","mini-batch training finished\n","loss/total 0.059318553656339645\n","loss/total 0.5607238411903381\n","loss/total 0.3552083969116211\n","loss/total 0.14118307828903198\n","loss/total 0.142561674118042\n","loss/total 0.07376289367675781\n","loss/total -0.06843690574169159\n","loss/total 0.3324283957481384\n","loss/total 0.04680129140615463\n","loss/total 0.2577834725379944\n","loss/total 0.044760674238204956\n","loss/total 0.15875506401062012\n","loss/total -0.38624632358551025\n","loss/total 1.067981243133545\n","loss/total -0.12536951899528503\n","loss/total -0.04219091683626175\n","loss/total 0.7336878776550293\n","loss/total -0.5979575514793396\n","loss/total -0.07694530487060547\n","loss/total 0.352499395608902\n","loss/total 0.03750155121088028\n","loss/total 0.395508348941803\n","loss/total -0.026183702051639557\n","loss/total -0.12311431765556335\n","loss/total -0.22815006971359253\n","loss/total -0.042544394731521606\n","loss/total 0.3390437066555023\n","loss/total 0.1320127248764038\n","loss/total 0.3714279532432556\n","loss/total -0.08718086034059525\n","loss/total 0.007024608552455902\n","loss/total 0.008999951183795929\n","mini-batch training finished\n","loss/total 0.5635951161384583\n","loss/total 0.3031620979309082\n","loss/total 0.5356185436248779\n","loss/total -0.2874445617198944\n","loss/total -0.4391050636768341\n","loss/total -0.006590045988559723\n","loss/total 0.13965272903442383\n","loss/total 0.026231545954942703\n","loss/total -0.6615694761276245\n","loss/total 0.17816342413425446\n","loss/total -0.4801316261291504\n","loss/total -0.669839084148407\n","loss/total 0.8054021000862122\n","loss/total 0.5007930994033813\n","loss/total 0.18132524192333221\n","loss/total 0.11472529172897339\n","loss/total 0.3249676823616028\n","loss/total -0.04571087658405304\n","loss/total -0.30271661281585693\n","loss/total -0.1325555443763733\n","loss/total 0.5527664422988892\n","loss/total -0.182159423828125\n","loss/total 0.544696569442749\n","loss/total -1.0337707996368408\n","loss/total -0.7565733194351196\n","loss/total -0.3030592203140259\n","loss/total 0.556839108467102\n","loss/total 0.2915329933166504\n","loss/total 0.13284265995025635\n","loss/total 0.4788151979446411\n","loss/total -0.7096517086029053\n","loss/total 0.10265576839447021\n","mini-batch training finished\n","loss/total 0.8632408380508423\n","loss/total 0.2061440646648407\n","loss/total 0.07013286650180817\n","loss/total 0.09070102870464325\n","loss/total -0.11621345579624176\n","loss/total -0.1168464869260788\n","loss/total 0.290986567735672\n","loss/total -0.19470295310020447\n","loss/total 0.03745946288108826\n","loss/total -0.33818909525871277\n","loss/total -0.4340989291667938\n","loss/total -0.15474025905132294\n","loss/total 0.0044158995151519775\n","loss/total 0.6466566324234009\n","loss/total -0.38332676887512207\n","loss/total 0.7967159748077393\n","loss/total -0.05760861560702324\n","loss/total 0.31468310952186584\n","loss/total 0.24936813116073608\n","loss/total -0.33808955550193787\n","loss/total -0.26602834463119507\n","loss/total 0.18139280378818512\n","loss/total 0.10037059336900711\n","loss/total -0.28785210847854614\n","loss/total -0.4656297564506531\n","loss/total 0.3953086733818054\n","loss/total -0.012509539723396301\n","loss/total 0.006331495940685272\n","loss/total -0.5498313307762146\n","loss/total 0.3053872883319855\n","loss/total 0.09881846606731415\n","loss/total 0.0665777325630188\n","mini-batch training finished\n","loss/total 0.4344693720340729\n","loss/total -0.4824613630771637\n","loss/total 0.20975419878959656\n","loss/total 0.41855427622795105\n","loss/total -0.022537335753440857\n","loss/total 0.302717387676239\n","loss/total 0.7372550964355469\n","loss/total 0.05304133519530296\n","loss/total -0.11408990621566772\n","loss/total 0.95067298412323\n","loss/total 0.0010285880416631699\n","loss/total -0.3143852949142456\n","loss/total 0.5731832981109619\n","loss/total -0.22870343923568726\n","loss/total -0.10785623639822006\n","loss/total 0.398969829082489\n","loss/total 0.0325465053319931\n","loss/total 0.597670316696167\n","loss/total -0.43295589089393616\n","loss/total 0.2163679599761963\n","loss/total 0.39773768186569214\n","loss/total -0.1506720781326294\n","loss/total 0.670569896697998\n","loss/total -0.8009186387062073\n","loss/total -0.17165237665176392\n","loss/total 0.33982715010643005\n","loss/total -0.04289177432656288\n","loss/total -0.008794456720352173\n","loss/total -0.07733167707920074\n","loss/total 0.4042825698852539\n","loss/total 0.12084877490997314\n","loss/total -0.025222569704055786\n","mini-batch training finished\n","loss/total -0.24148541688919067\n","loss/total 0.21639567613601685\n","loss/total 0.1669597625732422\n","loss/total 0.6315736770629883\n","loss/total 0.01930760219693184\n","loss/total 0.24076730012893677\n","loss/total -0.37750911712646484\n","loss/total 0.16626951098442078\n","loss/total -0.7884693145751953\n","loss/total 0.0008241310715675354\n","loss/total -0.4550241529941559\n","loss/total 0.4517350494861603\n","loss/total 0.4595637917518616\n","loss/total 0.1437867134809494\n","loss/total -0.35557785630226135\n","loss/total 0.22289007902145386\n","loss/total 0.1073194220662117\n","loss/total -0.5520820021629333\n","loss/total -0.03806159645318985\n","loss/total -0.3502715229988098\n","loss/total 0.5999736189842224\n","loss/total 0.06015999615192413\n","loss/total 0.05412282794713974\n","loss/total -0.19265376031398773\n","loss/total -0.5658712387084961\n","loss/total 0.3435617983341217\n","loss/total -0.5797967314720154\n","loss/total 0.37435945868492126\n","loss/total 0.0024007782340049744\n","loss/total 0.18134868144989014\n","loss/total 0.3435811400413513\n","loss/total -0.483406662940979\n","mini-batch training finished\n","loss/total 0.21190598607063293\n","loss/total -0.2957272529602051\n","loss/total 0.5339585542678833\n","loss/total 0.023379188030958176\n","loss/total 0.34795793890953064\n","loss/total -0.1570545732975006\n","loss/total -0.1917378306388855\n","loss/total -0.1435360610485077\n","loss/total -0.17543452978134155\n","loss/total -0.45148536562919617\n","loss/total -0.3596590757369995\n","loss/total 0.5949366092681885\n","loss/total -0.36192259192466736\n","loss/total -0.4244229793548584\n","loss/total -0.1328185796737671\n","loss/total 0.48545485734939575\n","loss/total 0.02462637424468994\n","loss/total -0.095761239528656\n","loss/total 0.8293668031692505\n","loss/total -0.5083238482475281\n","loss/total -0.6395267248153687\n","loss/total -0.21266883611679077\n","loss/total 0.22482460737228394\n","loss/total -0.7344367504119873\n","loss/total -0.3427056670188904\n","loss/total 0.04177762567996979\n","loss/total -0.5456554889678955\n","loss/total -0.151178777217865\n","loss/total -0.23951667547225952\n","loss/total 0.11121882498264313\n","loss/total -0.5325658321380615\n","loss/total 0.620885968208313\n","mini-batch training finished\n","loss/total 0.8535577654838562\n","loss/total 0.2507801949977875\n","loss/total 0.39243486523628235\n","loss/total 0.22875790297985077\n","loss/total 0.29668527841567993\n","loss/total -0.40115082263946533\n","loss/total 0.14412963390350342\n","loss/total -0.475896418094635\n","loss/total 0.09923427551984787\n","loss/total 0.045394882559776306\n","loss/total -0.09374816715717316\n","loss/total 0.12772081792354584\n","loss/total 0.3618927001953125\n","loss/total -0.005158029496669769\n","loss/total 0.04674100875854492\n","loss/total -0.0860656127333641\n","loss/total 0.027714353054761887\n","loss/total 0.05933159217238426\n","loss/total 0.22901955246925354\n","loss/total -0.004543684422969818\n","loss/total -0.0784209668636322\n","loss/total 0.178930401802063\n","loss/total 0.09990973025560379\n","loss/total -0.17552953958511353\n","loss/total -0.12496726214885712\n","loss/total 0.31242063641548157\n","loss/total 0.22448225319385529\n","loss/total -0.7862513065338135\n","loss/total 0.12588313221931458\n","loss/total 0.41214579343795776\n","loss/total 0.2111164629459381\n","loss/total -0.22785864770412445\n","mini-batch training finished\n","loss/total 0.2942033112049103\n","loss/total -0.45577114820480347\n","loss/total 0.06299532204866409\n","loss/total -0.0501975491642952\n","loss/total 0.6485951542854309\n","loss/total -0.14900869131088257\n","loss/total 0.516920268535614\n","loss/total -0.4660544693470001\n","loss/total -0.31110039353370667\n","loss/total -0.39863157272338867\n","loss/total 0.21122583746910095\n","loss/total -0.19962738454341888\n","loss/total -0.0700332298874855\n","loss/total -0.33027011156082153\n","loss/total -0.25344255566596985\n","loss/total 0.5401384234428406\n","loss/total -0.752477765083313\n","loss/total 0.38915789127349854\n","loss/total 0.25768327713012695\n","loss/total -0.228706493973732\n","loss/total -0.6234174966812134\n","loss/total 0.04654600843787193\n","loss/total -0.068506620824337\n","loss/total 0.01746324449777603\n","loss/total -0.2647443413734436\n","loss/total -0.4392358362674713\n","loss/total 0.3199567496776581\n","loss/total -0.11031396687030792\n","loss/total 0.27304014563560486\n","loss/total 0.23722846806049347\n","loss/total -0.4703209400177002\n","loss/total -0.8052760362625122\n","mini-batch training finished\n","loss/total -0.14883723855018616\n","loss/total -0.07605530321598053\n","loss/total 0.4772948920726776\n","loss/total 0.4051835238933563\n","loss/total -0.12204955518245697\n","loss/total 0.05765313655138016\n","loss/total -0.4902285933494568\n","loss/total 0.5464674830436707\n","loss/total -0.09173034876585007\n","loss/total 0.12260596454143524\n","loss/total 0.25973546504974365\n","loss/total -0.07214953750371933\n","loss/total 0.46671098470687866\n","loss/total -0.27393996715545654\n","loss/total -0.3812329173088074\n","loss/total -0.28686222434043884\n","loss/total 0.3081001043319702\n","loss/total 0.30322524905204773\n","loss/total -0.44222694635391235\n","loss/total 0.687190592288971\n","loss/total -0.5217921137809753\n","loss/total 0.10552164167165756\n","loss/total -0.12655827403068542\n","loss/total -0.5219736695289612\n","loss/total -0.29088571667671204\n","loss/total -0.4551761746406555\n","loss/total 0.624178946018219\n","loss/total -0.3208649456501007\n","loss/total -0.2866121530532837\n","loss/total -0.6929450035095215\n","loss/total 0.5464684963226318\n","loss/total 0.28044503927230835\n","mini-batch training finished\n","loss/total 0.06197873875498772\n","loss/total -0.19528605043888092\n","loss/total 0.20532314479351044\n","loss/total 0.019370779395103455\n","loss/total 0.9568871855735779\n","loss/total 0.46017175912857056\n","loss/total 0.13639840483665466\n","loss/total 0.33151739835739136\n","loss/total -0.10227131843566895\n","loss/total 0.04149243235588074\n","loss/total -0.07023587822914124\n","loss/total 0.35190004110336304\n","loss/total -0.22839078307151794\n","loss/total 0.7479087710380554\n","loss/total 0.19194555282592773\n","loss/total 0.22091218829154968\n","loss/total 0.6937445998191833\n","loss/total 0.2771648168563843\n","loss/total -0.19169287383556366\n","loss/total -0.3019331991672516\n","loss/total 0.1147865578532219\n","loss/total -0.03204743564128876\n","loss/total 0.5615237355232239\n","loss/total -0.004356563091278076\n","loss/total -0.15237239003181458\n","loss/total -0.08349692076444626\n","loss/total 0.07455100119113922\n","loss/total 0.5909721851348877\n","loss/total -0.15361620485782623\n","loss/total 0.546459436416626\n","loss/total -0.07813964784145355\n","loss/total 0.16779202222824097\n","mini-batch training finished\n","loss/total 0.048311203718185425\n","loss/total -0.16093458235263824\n","loss/total -0.2346256673336029\n","loss/total 0.4727829098701477\n","loss/total -0.18552327156066895\n","loss/total -0.06687751412391663\n","loss/total 0.3733978271484375\n","loss/total 0.7788183093070984\n","loss/total 0.11913981288671494\n","loss/total -0.08485034853219986\n","loss/total -0.30723124742507935\n","loss/total 0.2607039213180542\n","loss/total 0.10379721224308014\n","loss/total -0.29965949058532715\n","loss/total 0.006151542067527771\n","loss/total 0.09220226109027863\n","loss/total -0.5909537076950073\n","loss/total -0.567245364189148\n","loss/total 0.9367425441741943\n","loss/total -0.25814521312713623\n","loss/total 0.4776642620563507\n","loss/total 0.09761524200439453\n","loss/total -0.2016679346561432\n","loss/total -0.024529259651899338\n","loss/total -0.17383921146392822\n","loss/total -0.464996874332428\n","loss/total 0.6820770502090454\n","loss/total 0.01757153682410717\n","loss/total -0.26129642128944397\n","loss/total 0.13478028774261475\n","loss/total 0.036968909204006195\n","loss/total -0.31796911358833313\n","mini-batch training finished\n","loss/total 0.10422693192958832\n","loss/total -0.08561789244413376\n","loss/total -0.3207581639289856\n","loss/total -0.43298137187957764\n","loss/total 0.18672668933868408\n","loss/total 0.18063297867774963\n","loss/total 0.4313804507255554\n","loss/total -0.617462694644928\n","loss/total -0.5094817876815796\n","loss/total -0.04421335458755493\n","loss/total -0.06529432535171509\n","loss/total 0.024097058922052383\n","loss/total -0.8538753390312195\n","loss/total 0.014668166637420654\n","loss/total -0.2673052251338959\n","loss/total 0.29277464747428894\n","loss/total -0.14541161060333252\n","loss/total -0.12203330546617508\n","loss/total 0.4158923923969269\n","loss/total -0.5980413556098938\n","loss/total -0.3131506145000458\n","loss/total -0.34247633814811707\n","loss/total -0.39997878670692444\n","loss/total -0.20678609609603882\n","loss/total -0.058237917721271515\n","loss/total -0.5191398859024048\n","loss/total -0.055424757301807404\n","loss/total -0.9114307165145874\n","loss/total 0.1307404339313507\n","loss/total -0.16924861073493958\n","loss/total 0.0460677333176136\n","loss/total -0.3033450245857239\n","mini-batch training finished\n","loss/total 0.1562216579914093\n","loss/total 0.06881251931190491\n","loss/total 0.10784174501895905\n","loss/total 0.022652827203273773\n","loss/total -0.01560482382774353\n","loss/total -0.3046765625476837\n","loss/total 0.3265175223350525\n","loss/total 0.23905250430107117\n","loss/total -0.234709233045578\n","loss/total 0.5080156326293945\n","loss/total -0.050264306366443634\n","loss/total -0.4809815287590027\n","loss/total -0.09531810879707336\n","loss/total 0.10921937227249146\n","loss/total 0.04481806233525276\n","loss/total 0.1544359028339386\n","loss/total 0.17740824818611145\n","loss/total -0.12142316997051239\n","loss/total -0.2422184944152832\n","loss/total -0.10493224114179611\n","loss/total -0.08748667687177658\n","loss/total 0.24306368827819824\n","loss/total -0.16143974661827087\n","loss/total 0.015768639743328094\n","loss/total -0.11382272839546204\n","loss/total 0.22811327874660492\n","loss/total -0.009245354682207108\n","loss/total -0.020339466631412506\n","loss/total -0.10517290234565735\n","loss/total -0.5459088087081909\n","loss/total 0.025277525186538696\n","loss/total 0.16765710711479187\n","mini-batch training finished\n","loss/total -0.5901899933815002\n","loss/total 0.5811852216720581\n","loss/total -0.1682320386171341\n","loss/total 0.1007300317287445\n","loss/total 0.5005037784576416\n","loss/total -0.39567872881889343\n","loss/total 0.6574188470840454\n","loss/total 0.25793033838272095\n","loss/total 0.27651724219322205\n","loss/total -0.7878360748291016\n","loss/total 0.15729588270187378\n","loss/total 0.0004401206970214844\n","loss/total -0.45036637783050537\n","loss/total -0.047960564494132996\n","loss/total 0.15872037410736084\n","loss/total 0.46353477239608765\n","loss/total -0.7899383306503296\n","loss/total -0.09510748088359833\n","loss/total -0.07008092105388641\n","loss/total 0.2806045413017273\n","loss/total -0.2436782419681549\n","loss/total -0.0360238254070282\n","loss/total 0.29669737815856934\n","loss/total 0.3106561303138733\n","loss/total 0.25885361433029175\n","loss/total 0.5060059428215027\n","loss/total -0.12771663069725037\n","loss/total -0.5749897360801697\n","loss/total -0.10542647540569305\n","loss/total -0.2566695809364319\n","loss/total 0.07424991577863693\n","loss/total -0.25307875871658325\n","mini-batch training finished\n","loss/total 0.20718702673912048\n","loss/total 0.16302716732025146\n","loss/total -0.15946461260318756\n","loss/total -0.03479169309139252\n","loss/total 0.4853545129299164\n","loss/total 0.005388975143432617\n","loss/total 0.34510520100593567\n","loss/total -0.20887935161590576\n","loss/total 0.3777361214160919\n","loss/total -0.324982225894928\n","loss/total -0.08840783685445786\n","loss/total -0.03477257490158081\n","loss/total 0.61338210105896\n","loss/total -0.3317933678627014\n","loss/total -0.04760773479938507\n","loss/total 0.024318784475326538\n","loss/total 0.14185401797294617\n","loss/total 0.2449551224708557\n","loss/total 0.012234456837177277\n","loss/total 0.41302305459976196\n","loss/total -0.42631274461746216\n","loss/total -0.4128445088863373\n","loss/total 0.14496389031410217\n","loss/total -0.22285139560699463\n","loss/total -0.10007420182228088\n","loss/total 0.4221111834049225\n","loss/total 0.2132972627878189\n","loss/total -0.14446544647216797\n","loss/total -0.2404502034187317\n","loss/total -0.3797209858894348\n","loss/total -0.027251631021499634\n","loss/total -0.09949374198913574\n","mini-batch training finished\n","loss/total 0.26868873834609985\n","loss/total -0.11989948153495789\n","loss/total 0.520146369934082\n","loss/total 0.04773262143135071\n","loss/total 1.0562212467193604\n","loss/total -0.20630499720573425\n","loss/total -0.31045663356781006\n","loss/total -0.46943172812461853\n","loss/total -0.10804910957813263\n","loss/total -0.047218650579452515\n","loss/total 0.49604862928390503\n","loss/total 0.6049433946609497\n","loss/total -0.48465681076049805\n","loss/total 0.326703816652298\n","loss/total -0.6118842959403992\n","loss/total -0.20906579494476318\n","loss/total -0.12663206458091736\n","loss/total 0.25259459018707275\n","loss/total -0.10928268730640411\n","loss/total -0.4676359295845032\n","loss/total 0.17706391215324402\n","loss/total 0.002655990421772003\n","loss/total 0.41622281074523926\n","loss/total -0.38325944542884827\n","loss/total -0.015978369861841202\n","loss/total -0.4083648920059204\n","loss/total 0.16266921162605286\n","loss/total -0.06832803785800934\n","loss/total -0.5081350207328796\n","loss/total -0.0596156045794487\n","loss/total -0.10768043249845505\n","loss/total 0.7577357888221741\n","mini-batch training finished\n","loss/total 0.12143951654434204\n","loss/total 0.10414807498455048\n","loss/total -0.35288357734680176\n","loss/total 0.20528987050056458\n","loss/total 0.5247509479522705\n","loss/total 0.4208417236804962\n","loss/total 0.000863291323184967\n","loss/total -0.3775457739830017\n","loss/total 0.633232593536377\n","loss/total -0.058653324842453\n","loss/total -0.3084662854671478\n","loss/total -0.32590973377227783\n","loss/total 0.4331851303577423\n","loss/total -0.13455301523208618\n","loss/total 0.09123048931360245\n","loss/total -0.5810025930404663\n","loss/total 0.1801961064338684\n","loss/total -0.30948033928871155\n","loss/total 0.45601221919059753\n","loss/total -0.30560243129730225\n","loss/total 0.13611645996570587\n","loss/total 0.03116905689239502\n","loss/total 0.4347924292087555\n","loss/total -0.7865085005760193\n","loss/total -0.20307856798171997\n","loss/total 0.23497501015663147\n","loss/total -0.4576060175895691\n","loss/total 0.40614938735961914\n","loss/total -0.1334919035434723\n","loss/total 0.10909637808799744\n","loss/total -0.23482760787010193\n","loss/total 0.1364571452140808\n","mini-batch training finished\n","loss/total -0.09618625789880753\n","loss/total 0.3769826292991638\n","loss/total -0.2690845727920532\n","loss/total 0.13587220013141632\n","loss/total 0.9413089752197266\n","loss/total 0.5361142754554749\n","loss/total -0.06377138197422028\n","loss/total 0.32255417108535767\n","loss/total 0.9330310225486755\n","loss/total 0.2726925313472748\n","loss/total -0.539949357509613\n","loss/total 0.08496202528476715\n","loss/total -0.17514465749263763\n","loss/total 0.033373694866895676\n","loss/total 0.14180028438568115\n","loss/total 0.5238507986068726\n","loss/total -0.16842761635780334\n","loss/total 0.28828150033950806\n","loss/total -0.3933117985725403\n","loss/total 0.20729981362819672\n","loss/total 0.5514712929725647\n","loss/total -0.3556866943836212\n","loss/total -0.052833788096904755\n","loss/total 0.590745747089386\n","loss/total 0.25933393836021423\n","loss/total 0.32441505789756775\n","loss/total 0.054054565727710724\n","loss/total 0.3460814952850342\n","loss/total 0.2373937964439392\n","loss/total 0.18621423840522766\n","loss/total -0.5645434260368347\n","loss/total -0.05957985669374466\n","mini-batch training finished\n","loss/total 0.25247058272361755\n","loss/total -0.011382132768630981\n","loss/total -0.3794420659542084\n","loss/total 0.10903320461511612\n","loss/total 0.39807724952697754\n","loss/total 0.28728187084198\n","loss/total -0.03583618625998497\n","loss/total 0.18685050308704376\n","loss/total -0.0485948771238327\n","loss/total -0.5419429540634155\n","loss/total 0.5691554546356201\n","loss/total 0.19299006462097168\n","loss/total -0.009028926491737366\n","loss/total -0.5507279634475708\n","loss/total 0.3968268036842346\n","loss/total 0.23450607061386108\n","loss/total -0.38453009724617004\n","loss/total -0.5605565905570984\n","loss/total 0.6592775583267212\n","loss/total 0.5494841933250427\n","loss/total -0.20760652422904968\n","loss/total -0.024781420826911926\n","loss/total -0.5487861633300781\n","loss/total 0.26458603143692017\n","loss/total 0.3912923336029053\n","loss/total -0.4086132347583771\n","loss/total 0.09229545295238495\n","loss/total 0.4607105553150177\n","loss/total -0.28597861528396606\n","loss/total -0.4004618227481842\n","loss/total -0.5485667586326599\n","loss/total 0.6589821577072144\n","mini-batch training finished\n","loss/total -6.264448165893555e-05\n","loss/total 0.23867613077163696\n","loss/total -0.06661470234394073\n","loss/total 0.12805522978305817\n","loss/total 0.00589335709810257\n","loss/total 0.1115325316786766\n","loss/total 0.286741703748703\n","loss/total -0.3998225927352905\n","loss/total 0.30426856875419617\n","loss/total -0.5618368983268738\n","loss/total 0.29661625623703003\n","loss/total -0.06790003180503845\n","loss/total 0.025141801685094833\n","loss/total -0.13547472655773163\n","loss/total -0.7753618955612183\n","loss/total 0.3133265972137451\n","loss/total -0.10196000337600708\n","loss/total -0.19172757863998413\n","loss/total 0.2318120300769806\n","loss/total 0.1960698664188385\n","loss/total -0.27147212624549866\n","loss/total 0.023492105305194855\n","loss/total -0.747845470905304\n","loss/total 0.04625016823410988\n","loss/total -0.3931005597114563\n","loss/total -0.6375396847724915\n","loss/total -0.05912894755601883\n","loss/total 0.9859452247619629\n","loss/total -0.4126502573490143\n","loss/total -0.522891640663147\n","loss/total 0.03976833447813988\n","loss/total -0.12971998751163483\n","mini-batch training finished\n","loss/total -0.6317876577377319\n","loss/total 0.2958301305770874\n","loss/total -0.024043738842010498\n","loss/total 0.40016070008277893\n","loss/total -0.053615063428878784\n","loss/total -0.18206165730953217\n","loss/total 0.718927264213562\n","loss/total 0.27482831478118896\n","loss/total -0.38656479120254517\n","loss/total 0.054407212883234024\n","loss/total -0.13305070996284485\n","loss/total 0.41440820693969727\n","loss/total -0.004036471247673035\n","loss/total -0.06814049184322357\n","loss/total 0.4145120084285736\n","loss/total -0.08698108792304993\n","loss/total -0.0902792364358902\n","loss/total -0.20909518003463745\n","loss/total -0.3238829970359802\n","loss/total 0.3545679748058319\n","loss/total -0.5602003335952759\n","loss/total -0.028667010366916656\n","loss/total -0.017203018069267273\n","loss/total 0.7934013605117798\n","loss/total 0.06045279651880264\n","loss/total 0.1496826708316803\n","loss/total -0.27817511558532715\n","loss/total -0.42842262983322144\n","loss/total -0.048495106399059296\n","loss/total 0.5571197271347046\n","loss/total 0.033713072538375854\n","loss/total -0.10202140361070633\n","mini-batch training finished\n","loss/total 0.5101226568222046\n","loss/total -0.03694620728492737\n","loss/total -0.21723683178424835\n","loss/total -0.23532095551490784\n","loss/total 0.0029164254665374756\n","loss/total -0.3984191119670868\n","loss/total 0.8078519701957703\n","loss/total -0.07802020758390427\n","loss/total -0.061036329716444016\n","loss/total -0.31956619024276733\n","loss/total 0.516035795211792\n","loss/total -0.5083538293838501\n","loss/total -0.07356314361095428\n","loss/total -0.2100754976272583\n","loss/total 0.716558039188385\n","loss/total -0.6405898332595825\n","loss/total 0.02033223956823349\n","loss/total 0.10549149662256241\n","loss/total -0.45615044236183167\n","loss/total 0.2036280632019043\n","loss/total -0.5442730188369751\n","loss/total 0.11003641039133072\n","loss/total 0.17123034596443176\n","loss/total -0.2853018641471863\n","loss/total -0.32354989647865295\n","loss/total -0.05430803447961807\n","loss/total -0.6455963253974915\n","loss/total -0.1131313219666481\n","loss/total 0.5466377139091492\n","loss/total 0.08737869560718536\n","loss/total -0.11172312498092651\n","loss/total -0.12842240929603577\n","mini-batch training finished\n","loss/total -0.05911605805158615\n","loss/total 0.07001116871833801\n","loss/total 0.045049361884593964\n","loss/total -0.00817016139626503\n","loss/total 0.368476927280426\n","loss/total -0.1779700517654419\n","loss/total 0.35294267535209656\n","loss/total -0.22754094004631042\n","loss/total 0.0976538434624672\n","loss/total 0.04911506921052933\n","loss/total 0.23621314764022827\n","loss/total -0.2629433274269104\n","loss/total -0.08039715886116028\n","loss/total -0.35218971967697144\n","loss/total -0.18095755577087402\n","loss/total -0.06454598903656006\n","loss/total 0.06272965669631958\n","loss/total 0.16493196785449982\n","loss/total 0.6415420174598694\n","loss/total -0.2249133139848709\n","loss/total -0.6541752815246582\n","loss/total -0.11281149089336395\n","loss/total -0.23454800248146057\n","loss/total -0.4708515703678131\n","loss/total -0.24198518693447113\n","loss/total -0.04309336841106415\n","loss/total -0.3490285277366638\n","loss/total -0.3855495750904083\n","loss/total -0.057321250438690186\n","loss/total 0.396767258644104\n","loss/total -0.46375590562820435\n","loss/total 0.42491790652275085\n","mini-batch training finished\n","loss/total -0.024978354573249817\n","loss/total -0.010150521993637085\n","loss/total -0.16686511039733887\n","loss/total 0.33772218227386475\n","loss/total 0.0031711533665657043\n","loss/total -0.43135014176368713\n","loss/total 0.6046775579452515\n","loss/total 0.4929376542568207\n","loss/total 0.47940942645072937\n","loss/total -0.3168491721153259\n","loss/total -0.6088102459907532\n","loss/total -0.16875550150871277\n","loss/total -0.1804574877023697\n","loss/total -0.6470176577568054\n","loss/total 0.571813702583313\n","loss/total 0.6512746214866638\n","loss/total 0.18241828680038452\n","loss/total -0.07608051598072052\n","loss/total -0.2293834090232849\n","loss/total -0.30687612295150757\n","loss/total 0.7678690552711487\n","loss/total -0.06067328155040741\n","loss/total -0.5368287563323975\n","loss/total -0.23402394354343414\n","loss/total 0.024843597784638405\n","loss/total 0.2240498960018158\n","loss/total 0.07818564772605896\n","loss/total -0.608837366104126\n","loss/total -0.0368533656001091\n","loss/total 0.16816522181034088\n","loss/total -0.44910138845443726\n","loss/total 0.09757385402917862\n","mini-batch training finished\n","loss/total 0.7537133693695068\n","loss/total -0.05315117537975311\n","loss/total -0.425225168466568\n","loss/total -0.054319001734256744\n","loss/total 0.0008486509323120117\n","loss/total 0.289625883102417\n","loss/total 0.48811113834381104\n","loss/total 0.3927910625934601\n","loss/total 0.07618461549282074\n","loss/total 0.14755547046661377\n","loss/total 0.3291378319263458\n","loss/total 0.25379660725593567\n","loss/total 0.13445909321308136\n","loss/total 0.08456476032733917\n","loss/total -0.3125476837158203\n","loss/total -0.24853423237800598\n","loss/total 0.23453949391841888\n","loss/total -0.2133304476737976\n","loss/total -0.5340525507926941\n","loss/total 0.11248159408569336\n","loss/total -0.025847427546977997\n","loss/total 0.44317662715911865\n","loss/total -0.3822881579399109\n","loss/total 0.5504265427589417\n","loss/total -0.42967143654823303\n","loss/total 0.2975074052810669\n","loss/total -0.2682507336139679\n","loss/total -0.44349271059036255\n","loss/total 0.6375685930252075\n","loss/total 0.1427168846130371\n","loss/total 0.29750514030456543\n","loss/total -0.15328578650951385\n","mini-batch training finished\n","loss/total 0.3535916209220886\n","loss/total -0.48213547468185425\n","loss/total 0.6349883675575256\n","loss/total 0.44109225273132324\n","loss/total 0.5695061683654785\n","loss/total -0.25555065274238586\n","loss/total 0.08765316009521484\n","loss/total -0.14782920479774475\n","loss/total -0.378853440284729\n","loss/total -0.21889972686767578\n","loss/total -0.10751520097255707\n","loss/total 0.43906331062316895\n","loss/total 0.06933586299419403\n","loss/total -0.18293644487857819\n","loss/total -0.21090969443321228\n","loss/total 0.6069709658622742\n","loss/total -0.3929019272327423\n","loss/total -0.14897875487804413\n","loss/total 0.45596009492874146\n","loss/total -0.13670194149017334\n","loss/total 0.5130608677864075\n","loss/total 0.6045195460319519\n","loss/total -0.5021300315856934\n","loss/total -0.4068951904773712\n","loss/total -0.2856631577014923\n","loss/total -0.2357640415430069\n","loss/total 0.15103930234909058\n","loss/total -0.25283870100975037\n","loss/total 0.07181891798973083\n","loss/total -0.020186960697174072\n","loss/total 0.5918328762054443\n","loss/total -0.048779264092445374\n","mini-batch training finished\n","loss/total -0.6401183009147644\n","loss/total -0.18744242191314697\n","loss/total 0.9649880528450012\n","loss/total 0.3950304090976715\n","loss/total -0.4532596468925476\n","loss/total -0.05854671448469162\n","loss/total 0.6125002503395081\n","loss/total -0.4350033402442932\n","loss/total -0.3905527591705322\n","loss/total -0.2538760304450989\n","loss/total 0.3575650155544281\n","loss/total 0.48450714349746704\n","loss/total -0.2393723428249359\n","loss/total -0.22675326466560364\n","loss/total -0.08889633417129517\n","loss/total 0.08633528649806976\n","loss/total 0.17551767826080322\n","loss/total -0.28217387199401855\n","loss/total -0.20191217958927155\n","loss/total 0.389819473028183\n","loss/total 0.4546867311000824\n","loss/total 0.33362966775894165\n","loss/total -0.9630824327468872\n","loss/total -0.9171901941299438\n","loss/total -0.36546510457992554\n","loss/total -0.48561912775039673\n","loss/total 0.3578203022480011\n","loss/total -0.2661898136138916\n","loss/total 0.10177811980247498\n","loss/total -0.7620829343795776\n","loss/total 0.15202774107456207\n","loss/total 0.5130914449691772\n","mini-batch training finished\n","loss/total 0.61737060546875\n","loss/total -0.051264792680740356\n","loss/total 0.4863434433937073\n","loss/total 0.11499258875846863\n","loss/total 0.2500118017196655\n","loss/total -0.2094668745994568\n","loss/total 0.04244541749358177\n","loss/total 0.09481605887413025\n","loss/total -0.07292934507131577\n","loss/total -0.8819048404693604\n","loss/total 0.6880465745925903\n","loss/total 0.15244266390800476\n","loss/total -0.3887530267238617\n","loss/total 0.5029182434082031\n","loss/total 0.05701173096895218\n","loss/total 0.4175878167152405\n","loss/total -0.12180235981941223\n","loss/total 0.2257462441921234\n","loss/total 0.06156463176012039\n","loss/total 1.005263328552246\n","loss/total -0.41409891843795776\n","loss/total 0.03912358731031418\n","loss/total -0.37178313732147217\n","loss/total 0.024698540568351746\n","loss/total 0.08443859219551086\n","loss/total -0.7420353293418884\n","loss/total 0.5818281173706055\n","loss/total -0.027550630271434784\n","loss/total 0.012838739901781082\n","loss/total -0.08127735555171967\n","loss/total 0.23081263899803162\n","loss/total -0.06303505599498749\n","mini-batch training finished\n","loss/total -0.010898943990468979\n","loss/total -0.6128249168395996\n","loss/total 0.22578057646751404\n","loss/total 0.09493327140808105\n","loss/total 0.004833795130252838\n","loss/total 0.6319611668586731\n","loss/total -0.1672620177268982\n","loss/total 0.1061013787984848\n","loss/total -0.44078946113586426\n","loss/total -0.05694201588630676\n","loss/total -0.5154958963394165\n","loss/total 0.07397711277008057\n","loss/total -0.01705920696258545\n","loss/total 0.5721429586410522\n","loss/total -0.2291615903377533\n","loss/total -0.02113228291273117\n","loss/total 0.7265766859054565\n","loss/total 0.1115664392709732\n","loss/total -0.7058835029602051\n","loss/total -0.398874968290329\n","loss/total -0.49543997645378113\n","loss/total -0.0035691633820533752\n","loss/total -0.019849929958581924\n","loss/total 0.05566186457872391\n","loss/total -0.2545362710952759\n","loss/total 0.3980802893638611\n","loss/total -0.10623147338628769\n","loss/total 0.0939774140715599\n","loss/total -0.4812541604042053\n","loss/total 0.1512586772441864\n","loss/total -0.04759432375431061\n","loss/total -0.5220386981964111\n","mini-batch training finished\n","loss/total -0.03242073953151703\n","loss/total 0.3149585723876953\n","loss/total -0.25313031673431396\n","loss/total 0.5043172240257263\n","loss/total 0.19033096730709076\n","loss/total -0.2904016673564911\n","loss/total 0.4051818251609802\n","loss/total -0.6580836176872253\n","loss/total 0.08595820516347885\n","loss/total 0.30449748039245605\n","loss/total 0.33917057514190674\n","loss/total -0.4555172920227051\n","loss/total -0.013928931206464767\n","loss/total -0.8476204872131348\n","loss/total 0.25835418701171875\n","loss/total -0.2867765724658966\n","loss/total -0.45800915360450745\n","loss/total 0.27450746297836304\n","loss/total -0.22135880589485168\n","loss/total 0.1859463006258011\n","loss/total -0.3337979316711426\n","loss/total -0.029880620539188385\n","loss/total 0.26016074419021606\n","loss/total -0.47758758068084717\n","loss/total -0.14746487140655518\n","loss/total -0.10608243942260742\n","loss/total 0.4081254303455353\n","loss/total -0.08032810688018799\n","loss/total 0.06949794292449951\n","loss/total -0.00943724438548088\n","loss/total -0.16024094820022583\n","loss/total -0.8676261901855469\n","mini-batch training finished\n","loss/total -0.15607954561710358\n","loss/total -0.02022167295217514\n","loss/total 0.11471333354711533\n","loss/total 0.3442496061325073\n","loss/total 0.01658071205019951\n","loss/total 0.4057428538799286\n","loss/total 0.640631377696991\n","loss/total -0.7001022100448608\n","loss/total 0.4722142219543457\n","loss/total 0.386696994304657\n","loss/total -0.3869604468345642\n","loss/total -0.5483449697494507\n","loss/total 0.08452450484037399\n","loss/total -0.15155497193336487\n","loss/total 0.03465599566698074\n","loss/total -0.46218669414520264\n","loss/total 0.28003424406051636\n","loss/total 0.01161513477563858\n","loss/total -0.2634481191635132\n","loss/total 0.916477620601654\n","loss/total 0.08024516701698303\n","loss/total -0.16947217285633087\n","loss/total -0.12054864317178726\n","loss/total -0.9783124923706055\n","loss/total -0.2037389576435089\n","loss/total 0.2560320198535919\n","loss/total -0.11984966695308685\n","loss/total -0.03958602622151375\n","loss/total -0.19317494332790375\n","loss/total -0.4886864125728607\n","loss/total 0.49887657165527344\n","loss/total -0.5187405347824097\n","mini-batch training finished\n","loss/total 1.2111122608184814\n","loss/total 0.04877946153283119\n","loss/total 0.6535161733627319\n","loss/total -0.13863177597522736\n","loss/total -0.15068216621875763\n","loss/total -0.1561986654996872\n","loss/total 0.14524589478969574\n","loss/total 0.04993666335940361\n","loss/total -0.10859502851963043\n","loss/total 0.0805106908082962\n","loss/total 0.5341678857803345\n","loss/total -0.515245795249939\n","loss/total 0.9199053049087524\n","loss/total -0.2568313777446747\n","loss/total 0.43228352069854736\n","loss/total -0.05267836153507233\n","loss/total 0.3407105505466461\n","loss/total 0.3836691081523895\n","loss/total -0.4457078278064728\n","loss/total -0.37857285141944885\n","loss/total -0.34000083804130554\n","loss/total -0.1545857936143875\n","loss/total 0.8459469079971313\n","loss/total 0.3145027756690979\n","loss/total -0.3320176303386688\n","loss/total 0.3256080746650696\n","loss/total -0.12659752368927002\n","loss/total -0.13895836472511292\n","loss/total 1.0200473070144653\n","loss/total -0.2296484261751175\n","loss/total -0.5317822098731995\n","loss/total 0.6709944009780884\n","mini-batch training finished\n","loss/total -0.056193120777606964\n","loss/total 0.7225450277328491\n","loss/total 0.16772019863128662\n","loss/total 0.09180015325546265\n","loss/total 0.02821875736117363\n","loss/total 0.21161513030529022\n","loss/total -0.06316015869379044\n","loss/total -0.21013914048671722\n","loss/total -0.5452876091003418\n","loss/total 0.24844643473625183\n","loss/total -0.15501540899276733\n","loss/total -0.4658924341201782\n","loss/total 0.38282132148742676\n","loss/total 0.09758618474006653\n","loss/total 0.4779587686061859\n","loss/total -0.3505104184150696\n","loss/total 0.18764039874076843\n","loss/total -0.0020226873457431793\n","loss/total -0.0796593725681305\n","loss/total -0.30634012818336487\n","loss/total 0.29154232144355774\n","loss/total -0.45054295659065247\n","loss/total -0.4854277968406677\n","loss/total 0.37670567631721497\n","loss/total 0.20658338069915771\n","loss/total 0.30517345666885376\n","loss/total 0.35594508051872253\n","loss/total -0.32328665256500244\n","loss/total 0.10630762577056885\n","loss/total -0.7540055513381958\n","loss/total -0.39956602454185486\n","loss/total 0.019774941727519035\n","mini-batch training finished\n","loss/total 0.0363941416144371\n","loss/total 0.3668448030948639\n","loss/total -0.10670238733291626\n","loss/total 0.20621070265769958\n","loss/total 0.14870288968086243\n","loss/total 0.46694108843803406\n","loss/total 0.4503709673881531\n","loss/total -0.1319618970155716\n","loss/total -0.19165824353694916\n","loss/total 0.021224096417427063\n","loss/total 0.2695944607257843\n","loss/total 0.009501341730356216\n","loss/total -0.8676016926765442\n","loss/total 0.41398757696151733\n","loss/total 0.09568570554256439\n","loss/total 0.7423489093780518\n","loss/total 0.051924508064985275\n","loss/total 0.1600545048713684\n","loss/total 0.3575524091720581\n","loss/total 0.4155225455760956\n","loss/total 0.1293172687292099\n","loss/total -0.7565510869026184\n","loss/total 0.06250914186239243\n","loss/total -0.35405433177948\n","loss/total -0.41905349493026733\n","loss/total -0.2825535535812378\n","loss/total 0.24314847588539124\n","loss/total -0.5683857798576355\n","loss/total -0.12555041909217834\n","loss/total 0.2769051790237427\n","loss/total 0.6866482496261597\n","loss/total 0.20394545793533325\n","mini-batch training finished\n","loss/total 0.1675061285495758\n","loss/total 0.36440396308898926\n","loss/total 0.3265560567378998\n","loss/total -0.2916771471500397\n","loss/total -0.4966222643852234\n","loss/total 0.5284484028816223\n","loss/total -0.3530235290527344\n","loss/total 0.43803539872169495\n","loss/total -0.4343189597129822\n","loss/total -0.6623456478118896\n","loss/total 0.44310086965560913\n","loss/total 0.13113611936569214\n","loss/total 0.5614976286888123\n","loss/total 0.48557981848716736\n","loss/total -0.4836534559726715\n","loss/total -0.04856908321380615\n","loss/total -0.6179616451263428\n","loss/total 0.005019147880375385\n","loss/total 0.36479848623275757\n","loss/total 0.033927448093891144\n","loss/total 0.8049831390380859\n","loss/total -0.06115912273526192\n","loss/total -0.48973920941352844\n","loss/total -0.5251172780990601\n","loss/total 0.15011292695999146\n","loss/total 0.11497022211551666\n","loss/total 0.5351651310920715\n","loss/total -0.4336645007133484\n","loss/total -0.10197427123785019\n","loss/total -0.4411579966545105\n","loss/total -0.17942246794700623\n","loss/total -0.43166282773017883\n","mini-batch training finished\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-2776564252>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mnew_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_min_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_max_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mgeneration_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_new_tokens\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             query_response = model.generate(\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_attention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-4268667535>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2596\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2597\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2598\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2599\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3558\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3560\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3562\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, cache_position, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1231\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Validation"],"metadata":{"id":"p91mWY7ZAMw9"}},{"cell_type":"code","source":["len(tokenized_dataset_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CUEfXiPmOybE","executionInfo":{"status":"ok","timestamp":1749832603551,"user_tz":-60,"elapsed":5,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"dac6e4e2-4343-47c9-cf79-18f25f9789b0"},"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/plain":["807"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["val_gen_lengths = [0] * len(tokenized_dataset_val)\n","for i in range(len(tokenized_dataset_val)):\n","    val_gen_lengths[i] = random.choice(list(range(output_min_length, output_max_length)))"],"metadata":{"id":"1xdzy5XlO07I","executionInfo":{"status":"ok","timestamp":1749832604804,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["val_gen_lengths[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPM6f46xPyxO","executionInfo":{"status":"ok","timestamp":1749832606835,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"0c99e15c-5e64-4898-a2a6-df2fbe0a2bad"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[5, 8, 7, 11, 10, 8, 8, 9, 8, 10]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["def validate():\n","    scores = []\n","    for b, batch in enumerate(val_dataloader):\n","        # Generate_responses\n","        query_tensors = batch['input_ids']\n","        query_attention_masks = batch['attention_mask']\n","        for i, query in enumerate(query_tensors):\n","            query = query.to(device)\n","            query_attention_mask = query_attention_masks[i].to(device)\n","            new_tokens = val_gen_lengths[b * len(query_tensors) + i]\n","            generation_kwargs[\"max_new_tokens\"] = new_tokens\n","            query_response = model.generate(\n","                input_ids=query.unsqueeze(0),\n","                attention_mask=query_attention_mask.unsqueeze(0),\n","                **generation_kwargs\n","                ).squeeze(0)\n","            query_response_score = torch.cat([query_response, torch.tensor([REWARD_TOKEN_ID]).to(device)])\n","            attention_mask = torch.ones_like(query_response_score, dtype=torch.long)\n","            score = reward_model(query_response_score.unsqueeze(0), attention_mask.unsqueeze(0)).squeeze(0)[-1]\n","            score = 2 * (score - 0.5)\n","            scores.append(score.item())\n","    print('avg score:', sum(scores) / len(scores))"],"metadata":{"id":"y08Nx89CP2je","executionInfo":{"status":"ok","timestamp":1749832617720,"user_tz":-60,"elapsed":3,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["validate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvD7FCQ3SF7K","executionInfo":{"status":"ok","timestamp":1749832724521,"user_tz":-60,"elapsed":104656,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"39044774-344f-45d0-e171-355d2c23a733"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["avg score: 0.6572876147916621\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'ppo_model_epoch_1.pt')"],"metadata":{"id":"nOnXVMV7TaRy","executionInfo":{"status":"ok","timestamp":1749832738906,"user_tz":-60,"elapsed":7459,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["model_path = './sft_model_epoch_1'\n","model = ModelForCausalLMWithValueHead(model_path).to(device)"],"metadata":{"id":"rwf0VWEuSG0G","executionInfo":{"status":"ok","timestamp":1749832753082,"user_tz":-60,"elapsed":372,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["validate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40GywjqISiAW","executionInfo":{"status":"ok","timestamp":1749832854803,"user_tz":-60,"elapsed":100862,"user":{"displayName":"Ashwani Kumar","userId":"13347549760265504337"}},"outputId":"81882cfd-df4c-47a1-e46d-fc6dc35be6af"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["avg score: 0.07222306484626571\n"]}]}]}
